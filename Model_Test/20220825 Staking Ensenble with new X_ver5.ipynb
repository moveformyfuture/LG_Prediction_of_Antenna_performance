{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88c9f79",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784827d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from lightgbm import LGBMRegressor\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ab72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69084ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split_X_y(df):    \n",
    "    \"\"\"\n",
    "    @Description: split data into features and labels\n",
    "    @Param: df, pandas dataframe with columns starting with X for features and Y for labels\n",
    "    @Return: features and labels in pandas dataframes\n",
    "    \"\"\"\n",
    "    xs = df.filter(regex='X') # Input : X Feature\n",
    "    ys = df.filter(regex='Y') # Output : Y Feature\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_variance(df):\n",
    "    \"\"\"\n",
    "    @Description: check for zero_variance\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Return: names of the columns with zero variance\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if df[col].var() == 0:\n",
    "            result.append(col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3405de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlation(df, n=10):\n",
    "    \"\"\"\n",
    "    @Description: print out top correlated features\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: n, number of lines to print \n",
    "    @Return: pandas series\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    for idx1 in range(0, df.shape[1]):\n",
    "        for idx2 in range(0, idx1+1):\n",
    "            pairs.add((df.columns[idx1], df.columns[idx2]))\n",
    "    corr = df.corr().abs().unstack()\n",
    "    corr = corr.drop(labels=pairs).sort_values(ascending=False)\n",
    "    return corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8979dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg_nrmse(gt, preds):\n",
    "    \"\"\"\n",
    "    @Description: Metric used in this project\n",
    "    @Params1: gt, pandas dataframe\n",
    "    @Param2: preds, pandas dataframe\n",
    "    @Return: nrmse score\n",
    "    \"\"\"\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    preds = pd.DataFrame(preds)\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14):\n",
    "        rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f55a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_target(df):\n",
    "    \"\"\"\n",
    "    @Description: transform numeric target to binary\n",
    "    @Param1 df, pandas dataframe\n",
    "    @Param2 y_range, list of lists with min-max\n",
    "    @return labels, binary labels\n",
    "    \"\"\"\n",
    "    \n",
    "    ys = ['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', \n",
    "          'Y_06', 'Y_07', 'Y_08', 'Y_09', 'Y_10', \n",
    "          'Y_11', 'Y_12', 'Y_13', 'Y_14']\n",
    "    ys_bounds = [[0.2, 2], [0.2, 2.1], [0.2, 2.1], [7, 19], [22, 36.5], [-19.2, 19], \n",
    "                 [2.4, 4], [-29.2, -24], [-29.2, -24],[-30.6, -20], [19.6, 26.6], \n",
    "                 [-29.2, -24], [-29.2, -24], [-29.2, -24]]\n",
    "    labels = pd.DataFrame()\n",
    "    for idx in range(len(ys)):\n",
    "        y_series = ~df[ys[idx]].between(ys_bounds[idx][0], ys_bounds[idx][1], inclusive='both')\n",
    "        labels = pd.concat([labels, y_series.astype(int)], axis = 1)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70733c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_x = pd.read_csv('./test.csv')\n",
    "train_x, train_y = dataset_split_X_y(train_df)\n",
    "\n",
    "cols_with_zero_variance = zero_variance(train_x) # 분산이 0 (통과 여부)\n",
    "train_x = train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "test_x = test_x.drop(cols_with_zero_variance, axis = 1)\n",
    "\n",
    "train_x = train_x.drop(['X_10', 'X_11'], axis = 1) # 결측치가 많음 (결측치 = 0, 공지사항)\n",
    "test_x = test_x.drop(['X_10', 'X_11'], axis = 1)\n",
    "\n",
    "test_x = test_x.drop('ID', axis=1)\n",
    "y_binary_label = get_binary_target(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c57f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_splitted_data(binary_target, col, train_x_df, train_y_df, test_size = 0.2):\n",
    "    \n",
    "    train = pd.concat([train_x_df, train_y_df[col]], axis = 1) # 학습데이터에 수치형 타겟 칼럼 추가 \n",
    "    target = binary_target[col] # 칼럼 이진 데이터 (불량 vs. 정상)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=1, test_size=test_size, stratify=target)\n",
    "    \n",
    "    # 여기서 X_test, y_test 는 이진 데이터이므로 사용하지 않음\n",
    "    # 나눠진 데이터에서 불량/정상 데이터 비율 확인 \n",
    "    print(\"학습 데이터에서의 불량/정상 Ratio : \", sum(y_train ==0) / sum(y_train))\n",
    "    print(\"테스트 데이터에서의 불량/정상 Ratio: \", sum(y_test ==0) / sum(y_test))\n",
    "    \n",
    "    train_numerical_target = X_train[col] # 나눠진 *학습* 데이터에서 수치형 데이터 다시 추출\n",
    "    train_feature = X_train.drop([col], axis = 1) # 나눠진 *학습* 데이터에서 수치형 데이터 제거\n",
    "\n",
    "    test_numerical_target = X_test[col] # 나눠진 *테스트* 데이터에서 수치형 데이터 다시 추출\n",
    "    test_feature = X_test.drop([col], axis = 1) # 나눠진 *테스트* 데이터에서 수치형 데이터 제거\n",
    "    \n",
    "    return train_feature, train_numerical_target, test_feature, test_numerical_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "533faade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터에서의 불량/정상 Ratio :  25.82895850973751\n",
      "테스트 데이터에서의 불량/정상 Ratio:  25.854237288135593\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_feature, train_target, test_feature, test_target = get_splitted_data(y_binary_label, 'Y_01', train_x, train_y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4c673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0cf23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfcbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in df_indicator.columns:  # 불량 데이터 (행) 인덱스 추출\n",
    "    lst.append(df_indicator[df_indicator[i] == 1].index)\n",
    "    \n",
    "ans=set() # 유니크한 인덱스\n",
    "for i in lst:\n",
    "    for k in i:\n",
    "        ans.add(k)\n",
    "\n",
    "ans = list(ans)\n",
    "ans.sort()\n",
    "train_data_spec = train_df.loc[ans, :]  # 불량 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_norm = train_df.drop(train_data_spec.index) # 정상 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_norm))\n",
    "\n",
    "train_x_norm, train_y_norm = dataset_split_X_y(train_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89fcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_spec, train_y_spec = dataset_split_X_y(train_data_spec)\n",
    "print(len(train_x_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x_spec_plus_norm = pd.concat([train_x_norm, train_x_spec], axis = 0)\n",
    "new_train_y_spec_plus_norm = pd.concat([train_y_norm, train_y_spec], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ad929",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x_spec_plus_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646d538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msk1 = np.random.rand(len(train_x_norm)) < 0.8\n",
    "# msk2 = np.random.rand(len(train_x_spec)) < 0.8\n",
    "\n",
    "# tv_train_x_norm = train_x_norm[msk1]\n",
    "# tv_valid_x_norm = train_x_norm[~msk1]\n",
    "# tv_train_y_norm = train_y_norm[msk1]\n",
    "# tv_valid_y_norm = train_y_norm[~msk1]\n",
    "\n",
    "# tv_train_x_spec = train_x_spec[msk2]\n",
    "# tv_valid_x_spec = train_x_spec[~msk2]\n",
    "# tv_train_y_spec = train_y_spec[msk2]\n",
    "# tv_valid_y_spec = train_y_spec[~msk2]\n",
    "\n",
    "# tv_train_x = pd.concat([tv_train_x_norm, tv_train_x_spec], axis=0)\n",
    "# tv_valid_x = pd.concat([tv_valid_x_norm, tv_valid_x_spec], axis=0)\n",
    "# tv_train_y = pd.concat([tv_train_y_norm, tv_train_y_spec], axis=0)\n",
    "# tv_valid_y = pd.concat([tv_valid_y_norm, tv_valid_y_spec], axis=0)\n",
    "\n",
    "# tv_train_x.reset_index(inplace = True)\n",
    "# tv_valid_x.reset_index(inplace = True)\n",
    "# tv_train_y.reset_index(inplace = True)\n",
    "# tv_valid_y.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b62042",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50c724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fb1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tv_train_x))\n",
    "print(len(tv_train_y))\n",
    "print('-------------------------------------------')\n",
    "print(len(tv_valid_x))\n",
    "print(len(tv_valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babba192",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_x = tv_train_x.iloc[:, 1:]\n",
    "tv_train_y = tv_train_y.iloc[:, 1:]\n",
    "tv_valid_x = tv_valid_x.iloc[:, 1:]\n",
    "tv_valid_y = tv_valid_y.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ea767",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ddaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_with_zero_variance = zero_variance(tv_train_x) # 분산이 0 (통과 여부)\n",
    "#tv_train_x = tv_train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "#tv_valid_x = tv_train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "\n",
    "tv_train_x = tv_train_x.drop(['X_10', 'X_11'], axis = 1) # 결측치가 많음 (결측치 = 0, 공지사항)\n",
    "tv_valid_x = tv_valid_x.drop(['X_10', 'X_11'], axis = 1)\n",
    "\n",
    "#tv_valid_x = tv_valid_x.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tv_valid_x) + len(tv_train_x))\n",
    "print(len(tv_train_y) + len(tv_valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa03409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'min_child_samples': int(params['min_child_samples']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'subsample': '{:.3f}'.format(params['subsample']),\n",
    "        'min_split_gain': '{:.3f}'.format(params['min_split_gain']),\n",
    "        'scale_pos_weight': '{:.3f}'.format(params['scale_pos_weight']),\n",
    "        'reg_alpha': '{:.3f}'.format(params['reg_alpha']),\n",
    "        'reg_lambda': '{:.3f}'.format(params['reg_lambda']),\n",
    "        'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "    }\n",
    "    \n",
    "    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **params))\n",
    "    \n",
    "    loss = -cross_val_score(model, tv_train_x, tv_train_y, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(loss, params))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2148240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1000, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 100, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 100, 10),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 300, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.7),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 100),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 100),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 500,\n",
    "            rstate=np.random.default_rng(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02049b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'colsample_bytree': 0.572280100273023, 'learning_rate': 0.010283635038627429, 'max_depth': 180, 'min_child_samples': 135, 'min_split_gain': 0.04511227284338413, 'n_estimators': 900, 'num_leaves': 70, 'reg_alpha': 4.406681827912319, 'reg_lambda': 20.4785600448913, 'scale_pos_weight': 8.302374117433086, 'subsample': 0.1688669888026464}\n",
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "    \n",
    "loss = -cross_val_score(model, tv_train_x, tv_train_y, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "print(\"NRMSE Loss {:.5f} params {}\".format(loss, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tv_train_x.columns))\n",
    "print(len(tv_valid_x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'colsample_bytree': 0.572280100273023, 'learning_rate': 0.010283635038627429, 'max_depth': 180, 'min_child_samples': 135, 'min_split_gain': 0.04511227284338413, 'n_estimators': 900, 'num_leaves': 70, 'reg_alpha': 4.406681827912319, 'reg_lambda': 20.4785600448913, 'scale_pos_weight': 8.302374117433086, 'subsample': 0.1688669888026464}\n",
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "model.fit(tv_train_x, tv_train_y)\n",
    "preds = model.predict(tv_valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c85a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a.columns:\n",
    "    print('{}  /  Min : {}    ,   Min : {}'.format(i, min(a[i]), max(a[i])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('data/validation_test_submission.csv')\n",
    "for idx, col in enumerate(submit.columns):\n",
    "    if col=='ID':\n",
    "        continue\n",
    "    submit[col] = preds[:,idx-1]\n",
    "#submit.to_csv('data/param_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()\n",
    "\n",
    "df_indicator = pd.DataFrame()\n",
    "\n",
    "for i, k in enumerate(submit.columns):\n",
    "    if k == 'ID':\n",
    "        continue\n",
    "    y_series = ~submit[k].between(y_feature_spec_info['최소'][i-1], y_feature_spec_info['최대'][i-1])\n",
    "    if i == 1:\n",
    "        df_indicator = y_series\n",
    "    else:\n",
    "        df_indicator = df_indicator + y_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485afac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_indicator.value_counts())\n",
    "df_indicator[df_indicator==True] = 1\n",
    "df_indicator[df_indicator==False] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f02f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_valid_x['X_57'] = df_indicator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffc49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_valid_x['X_57'] = tv_valid_x['X_57'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_valid_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ccbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tv_train_x))\n",
    "print(len(tv_valid_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e3b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best = {'colsample_bytree': 0.572280100273023, 'learning_rate': 0.010283635038627429, 'max_depth': 180, 'min_child_samples': 135, 'min_split_gain': 0.04511227284338413, 'n_estimators': 900, 'num_leaves': 70, 'reg_alpha': 4.406681827912319, 'reg_lambda': 20.4785600448913, 'scale_pos_weight': 8.302374117433086, 'subsample': 0.1688669888026464}\n",
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "    \n",
    "loss = -cross_val_score(model, tv_valid_x, tv_valid_y, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "print(\"NRMSE Loss {:.5f} params {}\".format(loss, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c546c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = submit.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf66776",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_nrmse(submit, tv_valid_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
