{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88c9f79",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784827d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from lightgbm import LGBMRegressor\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ab72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88c9794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split_X_y(df):    \n",
    "    \"\"\"\n",
    "    @Description: split data into features and labels\n",
    "    @Param: df, pandas dataframe with columns starting with X for features and Y for labels\n",
    "    @Return: features and labels in pandas dataframes\n",
    "    \"\"\"\n",
    "    xs = df.filter(regex='X') # Input : X Feature\n",
    "    ys = df.filter(regex='Y') # Output : Y Feature\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abc8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_variance(df):\n",
    "    \"\"\"\n",
    "    @Description: check for zero_variance\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Return: names of the columns with zero variance\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if df[col].var() == 0:\n",
    "            result.append(col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1192f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlation(df, n=10):\n",
    "    \"\"\"\n",
    "    @Description: print out top correlated features\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: n, number of lines to print \n",
    "    @Return: pandas series\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    for idx1 in range(0, df.shape[1]):\n",
    "        for idx2 in range(0, idx1+1):\n",
    "            pairs.add((df.columns[idx1], df.columns[idx2]))\n",
    "    corr = df.corr().abs().unstack()\n",
    "    corr = corr.drop(labels=pairs).sort_values(ascending=False)\n",
    "    return corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef9aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg_nrmse(gt, preds):\n",
    "    \"\"\"\n",
    "    @Description: Metric used in this project\n",
    "    @Params1: gt, pandas dataframe\n",
    "    @Param2: preds, pandas dataframe\n",
    "    @Return: nrmse score\n",
    "    \"\"\"\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    preds = pd.DataFrame(preds)\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14):\n",
    "        rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70733c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_10  X_11    0.908978\n",
      "X_14  X_18    0.860102\n",
      "X_15  X_18    0.858704\n",
      "X_19  X_21    0.855176\n",
      "X_14  X_15    0.846266\n",
      "X_20  X_22    0.831176\n",
      "X_24  X_26    0.816194\n",
      "X_41  X_43    0.798763\n",
      "X_25  X_27    0.775328\n",
      "X_17  X_18    0.758397\n",
      "X_26  X_28    0.750090\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_x = pd.read_csv('./test.csv')\n",
    "train_x, train_y = dataset_split_X_y(train_df)\n",
    "print( get_top_correlation(train_x, 11))\n",
    "cols_with_zero_variance = zero_variance(train_x)\n",
    "train_x = train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "test_x = test_x.drop(cols_with_zero_variance, axis = 1)\n",
    "highly_correlated = [i[1] for i in get_top_correlation(train_x, 11).index]\n",
    "train_x = train_x.drop(highly_correlated, axis = 1)\n",
    "\n",
    "test_x = test_x.drop(highly_correlated, axis = 1)\n",
    "test_x = test_x.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa03409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'min_child_samples': int(params['min_child_samples']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'subsample': '{:.3f}'.format(params['subsample']),\n",
    "        'min_split_gain': '{:.3f}'.format(params['min_split_gain']),\n",
    "        'scale_pos_weight': '{:.3f}'.format(params['scale_pos_weight']),\n",
    "        'reg_alpha': '{:.3f}'.format(params['reg_alpha']),\n",
    "        'reg_lambda': '{:.3f}'.format(params['reg_lambda']),\n",
    "        'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **params))\n",
    "    \n",
    "    loss = -cross_val_score(model, train_x, train_y, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(loss, params))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2148240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                   | 0/500 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1500, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 100, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 100, 10),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 300, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.7),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 100),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 100),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 500,\n",
    "            rstate=np.random.default_rng(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "for idx, col in enumerate(submit.columns):\n",
    "    if col=='ID':\n",
    "        continue\n",
    "    submit[col] = preds[:,idx-1]\n",
    "submit.to_csv('./submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff53b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
