{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88c9f79",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784827d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import optuna\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from hyperopt import fmin, hp, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae8bb1",
   "metadata": {},
   "source": [
    "## Usable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf020df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b417e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split_X_y(df):    \n",
    "    \"\"\"\n",
    "    @Description: split data into features and labels\n",
    "    @Param: df, pandas dataframe with columns starting with X for features and Y for labels\n",
    "    @Return: features and labels in pandas dataframes\n",
    "    \"\"\"\n",
    "    xs = df.filter(regex='X') # Input : X Feature\n",
    "    ys = df.filter(regex='Y') # Output : Y Feature\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_NAs(df, show=False):\n",
    "    \"\"\"\n",
    "    @Description: checks for the NAs in the dataframe\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: show, boolean indicating whether NaN data are also necessary as a part of the output\n",
    "    @Return: name of the columns with NaN\n",
    "    \"\"\"\n",
    "    nan_values = df.loc[:, df.isnull().any()]\n",
    "    if show:\n",
    "        return df[df.isna().any(axis=1)]\n",
    "    return list(nan_values.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_label_bound(df, labels, bound):\n",
    "    \"\"\"\n",
    "    @Description: check bound is inbetween min and max\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: labels, list of column names \n",
    "    @Param3: thres: list of bounds\n",
    "    @Return: names of the columns not within the bound\n",
    "    \"\"\"\n",
    "    n = len(labels)\n",
    "    result = []\n",
    "    for idx in range(n):\n",
    "        col = labels[idx]\n",
    "        thres = bound[idx]\n",
    "        extracted_column = df[col]\n",
    "        if not extracted_column.between(thres[0], thres[1]).all():\n",
    "            result.append(labels[idx])\n",
    "    if len(result) == 0:\n",
    "        print('everything is within the bound')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89853f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_variance(df):\n",
    "    \"\"\"\n",
    "    @Description: check for zero_variance\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Return: names of the columns with zero variance\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if df[col].var() == 0:\n",
    "            result.append(col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlation(df, n=10):\n",
    "    \"\"\"\n",
    "    @Description: print out top correlated features\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: n, number of lines to print \n",
    "    @Return: pandas series\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    for idx1 in range(0, df.shape[1]):\n",
    "        for idx2 in range(0, idx1+1):\n",
    "            pairs.add((df.columns[idx1], df.columns[idx2]))\n",
    "    corr = df.corr().abs().unstack()\n",
    "    corr = corr.drop(labels=pairs).sort_values(ascending=False)\n",
    "    return corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacent_histogram_boxplot(feature_var, figsize = (7, 5)):\n",
    "    \"\"\"\n",
    "    @Description: plot histogram and boxplot in next to each other\n",
    "    @Param1: feature_var, pandas series \n",
    "    @Param2: figsize, size of the figure \n",
    "    \"\"\"\n",
    "    fig, (hist_plot, box_plot) = plt.subplots(nrows=2, sharex=True, gridspec_kw={'height_ratios':(.85,.15)}, figsize=figsize)\n",
    "    sns.distplot(feature_var, kde=True, ax=hist_plot, kde_kws= {\"linewidth\":1.5}) \n",
    "    sns.boxplot(feature_var, ax=box_plot, linewidth = 1, width = 0.5)\n",
    "    hist_plot.set_ylabel('')    \n",
    "    hist_plot.set_xlabel('')\n",
    "    box_plot.set_xlabel('')\n",
    "    hist_plot.tick_params(labelsize=8)\n",
    "    box_plot.tick_params(labelsize=8)\n",
    "    fig.suptitle(feature_var.name, fontsize = 10)\n",
    "    hist_plot.axvline(np.mean(feature_var),color='red',linestyle='-',lw = 1.5)\n",
    "    hist_plot.axvline(np.median(feature_var),color='green',linestyle='--',lw = 1.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg_nrmse(gt, preds):\n",
    "    \"\"\"\n",
    "    @Description: Metric used in this project\n",
    "    @Params1: gt, pandas dataframe\n",
    "    @Param2: preds, pandas dataframe\n",
    "    @Return: nrmse score\n",
    "    \"\"\"\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    preds = pd.DataFrame(preds)\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14):\n",
    "        rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_zscore(data, threshold = 3):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    zs = [(y - mean) / std for y in data]\n",
    "    masks = np.where(np.abs(zs) > threshold)\n",
    "    return masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicates(l):\n",
    "    s = set()\n",
    "    s_add = s.add\n",
    "    s_twice = set( x for x in l if x in s or s_add(x) )\n",
    "    return list(s_twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2009c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ys = ['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', \n",
    "#       'Y_06', 'Y_07', 'Y_08', 'Y_09', 'Y_10', \n",
    "#       'Y_11', 'Y_12', 'Y_13', 'Y_14']\n",
    "# ys_bounds = [[0.2, 2], [0.2, 2.1], [0.2, 2.1], \n",
    "#              [7, 19], [22, 36.5], [-19.2, 19], \n",
    "#              [2.4, 4], [-29.2, -24], [-29.2, -24],\n",
    "#              [-30.6, -20], [19.6, 26.6], [-29.2, -24],\n",
    "#              [-29.2, -24], [-29.2, -24]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ab0eb",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_x = pd.read_csv('./test.csv')\n",
    "train_x, train_y = dataset_split_X_y(train_df)\n",
    "\n",
    "cols_with_zero_variance = zero_variance(train_x)\n",
    "train_x = train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "test_x = test_x.drop(cols_with_zero_variance, axis = 1)\n",
    "\n",
    "test_x = test_x.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in train_x.columns:\n",
    "    result.extend(find_outlier_zscore(train_x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = duplicates(result)\n",
    "need_to_remove = train_x.index.isin(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x[~need_to_remove]\n",
    "train_y = train_y[~need_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e376c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlated Feature 지우기\n",
    "print( get_top_correlation(train_x, 10))\n",
    "highly_correlated = [i[1] for i in get_top_correlation(train_x, 10).index]\n",
    "train_x = train_x.drop(highly_correlated, axis = 1)\n",
    "test_x = test_x.drop(highly_correlated, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aed546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'min_child_samples': int(params['min_child_samples']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'subsample': '{:.3f}'.format(params['subsample']),\n",
    "        'min_split_gain': '{:.3f}'.format(params['min_split_gain']),\n",
    "        'scale_pos_weight': '{:.3f}'.format(params['scale_pos_weight']),\n",
    "        'reg_alpha': '{:.3f}'.format(params['reg_alpha']),\n",
    "        'reg_lambda': '{:.3f}'.format(params['reg_lambda']),\n",
    "        'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    model = MultiOutputRegressor(LGBMRegressor(\n",
    "        n_jobs = -1,\n",
    "        random_state = 1,\n",
    "        **params\n",
    "    ))\n",
    "    \n",
    "    loss = -cross_val_score(model, train_x, train_y, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(loss, params))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0991f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1500, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 50, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 100, 10),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 150, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.7),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 100),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 100),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 300,\n",
    "            rstate=np.random.default_rng(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d622b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputRegressor(LGBMRegressor(\n",
    "                                n_jobs = -1,\n",
    "                                random_state = 1,\n",
    "                                **best\n",
    "                              ))\n",
    "model.fit(train_x, train_y)\n",
    "preds = model.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aceff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "for idx, col in enumerate(submit.columns):\n",
    "    if col=='ID':\n",
    "        continue\n",
    "    submit[col] = preds[:,idx-1]\n",
    "submit.to_csv('./submission_7.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
