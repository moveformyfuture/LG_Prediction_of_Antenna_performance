{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35443,
     "status": "ok",
     "timestamp": 1661210001660,
     "user": {
      "displayName": "Jaewoo Choi",
      "userId": "05968598841946004036"
     },
     "user_tz": -540
    },
    "id": "V1s0gwOEkAYi",
    "outputId": "f807e119-a943-48cd-dd33-657e38379608"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\dev\\miniconda3\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (1.9.0)\n",
      "Requirement already satisfied: PyYAML in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: colorlog in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (6.6.0)\n",
      "Requirement already satisfied: alembic in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: numpy in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (1.23.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: cliff in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (4.0.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (1.4.40)\n",
      "Requirement already satisfied: tqdm in c:\\dev\\miniconda3\\lib\\site-packages (from optuna) (4.63.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\dev\\miniconda3\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\dev\\miniconda3\\lib\\site-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
      "Requirement already satisfied: Mako in c:\\dev\\miniconda3\\lib\\site-packages (from alembic->optuna) (1.2.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in c:\\dev\\miniconda3\\lib\\site-packages (from cliff->optuna) (4.0.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in c:\\dev\\miniconda3\\lib\\site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in c:\\dev\\miniconda3\\lib\\site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\dev\\miniconda3\\lib\\site-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\dev\\miniconda3\\lib\\site-packages (from cliff->optuna) (4.12.0)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\dev\\miniconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\dev\\miniconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: pyreadline3 in c:\\dev\\miniconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: pyperclip>=1.6 in c:\\dev\\miniconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\dev\\miniconda3\\lib\\site-packages (from importlib-metadata>=4.4->cliff->optuna) (3.8.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\dev\\miniconda3\\lib\\site-packages (from stevedore>=2.0.1->cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: colorama in c:\\dev\\miniconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\dev\\miniconda3\\lib\\site-packages (from Mako->alembic->optuna) (2.1.1)\n",
      "Collecting catboost\n",
      "  Using cached catboost-1.0.6-cp39-none-win_amd64.whl (73.9 MB)\n",
      "Requirement already satisfied: six in c:\\dev\\miniconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\dev\\miniconda3\\lib\\site-packages (from catboost) (1.9.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\dev\\miniconda3\\lib\\site-packages (from catboost) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\dev\\miniconda3\\lib\\site-packages (from catboost) (1.23.2)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\dev\\miniconda3\\lib\\site-packages (from catboost) (3.5.3)\n",
      "Requirement already satisfied: plotly in c:\\dev\\miniconda3\\lib\\site-packages (from catboost) (5.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\dev\\miniconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\dev\\miniconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (4.35.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\dev\\miniconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.0.6 graphviz-0.20.1\n",
      "Requirement already satisfied: skranger in c:\\dev\\miniconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\dev\\miniconda3\\lib\\site-packages (from skranger) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\dev\\miniconda3\\lib\\site-packages (from scikit-learn>=1.0->skranger) (1.23.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\dev\\miniconda3\\lib\\site-packages (from scikit-learn>=1.0->skranger) (1.9.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\dev\\miniconda3\\lib\\site-packages (from scikit-learn>=1.0->skranger) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\dev\\miniconda3\\lib\\site-packages (from scikit-learn>=1.0->skranger) (3.1.0)\n",
      "Collecting ngboost\n",
      "  Downloading ngboost-0.3.12-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in c:\\dev\\miniconda3\\lib\\site-packages (from ngboost) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\dev\\miniconda3\\lib\\site-packages (from ngboost) (1.23.2)\n",
      "Requirement already satisfied: tqdm>=4.3 in c:\\dev\\miniconda3\\lib\\site-packages (from ngboost) (4.63.0)\n",
      "Collecting lifelines>=0.25\n",
      "  Downloading lifelines-0.27.1-py3-none-any.whl (349 kB)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\dev\\miniconda3\\lib\\site-packages (from ngboost) (1.9.0)\n",
      "Requirement already satisfied: matplotlib>=3.0 in c:\\dev\\miniconda3\\lib\\site-packages (from lifelines>=0.25->ngboost) (3.5.3)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\dev\\miniconda3\\lib\\site-packages (from lifelines>=0.25->ngboost) (1.4.3)\n",
      "Collecting autograd>=1.3\n",
      "  Downloading autograd-1.4-py3-none-any.whl (48 kB)\n",
      "Collecting autograd-gamma>=0.3\n",
      "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
      "Collecting formulaic>=0.2.2\n",
      "  Downloading formulaic-0.4.0-py3-none-any.whl (76 kB)\n",
      "Collecting future>=0.15.2\n",
      "  Using cached future-0.18.2-py3-none-any.whl\n",
      "Collecting interface-meta<2.0.0,>=1.2.0\n",
      "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.2.0 in c:\\dev\\miniconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.3.0)\n",
      "Collecting astor>=0.8\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.0 in c:\\dev\\miniconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.14.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.35.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\dev\\miniconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\dev\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->lifelines>=0.25->ngboost) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\dev\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\dev\\miniconda3\\lib\\site-packages (from scikit-learn>=0.21->ngboost) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\dev\\miniconda3\\lib\\site-packages (from scikit-learn>=0.21->ngboost) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\dev\\miniconda3\\lib\\site-packages (from tqdm>=4.3->ngboost) (0.4.4)\n",
      "Building wheels for collected packages: autograd-gamma\n",
      "  Building wheel for autograd-gamma (setup.py): started\n",
      "  Building wheel for autograd-gamma (setup.py): finished with status 'done'\n",
      "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4048 sha256=c2dc1b38d7fe8bf302b74551336f95062849a8101b07997f195377d9f18220e3\n",
      "  Stored in directory: c:\\users\\cjpar\\appdata\\local\\pip\\cache\\wheels\\a8\\03\\64\\8557323821d25118c3a2dc1646996f7a962a8970d4b7d22473\n",
      "Successfully built autograd-gamma\n",
      "Installing collected packages: future, interface-meta, autograd, astor, formulaic, autograd-gamma, lifelines, ngboost\n",
      "Successfully installed astor-0.8.1 autograd-1.4 autograd-gamma-0.5.0 formulaic-0.4.0 future-0.18.2 interface-meta-1.3.0 lifelines-0.27.1 ngboost-0.3.12\n"
     ]
    }
   ],
   "source": [
    "!unzip /content/drive/MyDrive/Project/Dacon/lgauto/open.zip\n",
    "# !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "# !cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
    "!pip install optuna\n",
    "!pip install catboost\n",
    "!pip install skranger\n",
    "!pip install ngboost\n",
    "!pip install lightgbm\n",
    "!pip install xgboost\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pcG2aSVkkAVz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, Lasso, Ridge\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from skranger.ensemble import RangerForestRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "\n",
    "from hyperopt import fmin, hp, tpe\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8e67ifiDnv5w"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "  seed = 42\n",
    "  epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-ZK7vgIBkAS-"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "V8XIRg1wkAQW"
   },
   "outputs": [],
   "source": [
    "def dataset_split_X_y(df):    \n",
    "    \"\"\"\n",
    "    @Description: split data into features and labels\n",
    "    @Param: df, pandas dataframe with columns starting with X for features and Y for labels\n",
    "    @Return: features and labels in pandas dataframes\n",
    "    \"\"\"\n",
    "    xs = df.filter(regex='X') # Input : X Feature\n",
    "    ys = df.filter(regex='Y') # Output : Y Feature\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KBgkm1KPlYtZ"
   },
   "outputs": [],
   "source": [
    "def check_for_NAs(df, show=False):\n",
    "    \"\"\"\n",
    "    @Description: checks for the NAs in the dataframe\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: show, boolean indicating whether NaN data are also necessary as a part of the output\n",
    "    @Return: name of the columns with NaN\n",
    "    \"\"\"\n",
    "    nan_values = df.loc[:, df.isnull().any()]\n",
    "    if show:\n",
    "        return df[df.isna().any(axis=1)]\n",
    "    return list(nan_values.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZgMxozATlbCp"
   },
   "outputs": [],
   "source": [
    "def check_for_label_bound(df, labels, bound):\n",
    "    \"\"\"\n",
    "    @Description: check bound is inbetween min and max\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: labels, list of column names \n",
    "    @Param3: thres: list of bounds\n",
    "    @Return: names of the columns not within the bound\n",
    "    \"\"\"\n",
    "    n = len(labels)\n",
    "    result = []\n",
    "    for idx in range(n):\n",
    "        col = labels[idx]\n",
    "        thres = bound[idx]\n",
    "        extracted_column = df[col]\n",
    "        if not extracted_column.between(thres[0], thres[1]).all():\n",
    "            result.append(labels[idx])\n",
    "    if len(result) == 0:\n",
    "        print('everything is within the bound')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fA_w1Rt-kADH"
   },
   "outputs": [],
   "source": [
    "def zero_variance(df):\n",
    "    \"\"\"\n",
    "    @Description: check for zero_variance\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Return: names of the columns with zero variance\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if df[col].var() == 0:\n",
    "            result.append(col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NtEGKh0zlErb"
   },
   "outputs": [],
   "source": [
    "def get_top_correlation(df, n=10):\n",
    "    \"\"\"\n",
    "    @Description: print out top correlated features\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: n, number of lines to print \n",
    "    @Return: pandas series\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    for idx1 in range(0, df.shape[1]):\n",
    "        for idx2 in range(0, idx1+1):\n",
    "            pairs.add((df.columns[idx1], df.columns[idx2]))\n",
    "    corr = df.corr().abs().unstack()\n",
    "    corr = corr.drop(labels=pairs).sort_values(ascending=False)\n",
    "    return corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FlUrH-kLldrb"
   },
   "outputs": [],
   "source": [
    "def adjacent_histogram_boxplot(feature_var, figsize = (7, 5)):\n",
    "    \"\"\"\n",
    "    @Description: plot histogram and boxplot in next to each other\n",
    "    @Param1: feature_var, pandas series \n",
    "    @Param2: figsize, size of the figure \n",
    "    \"\"\"\n",
    "    fig, (hist_plot, box_plot) = plt.subplots(nrows=2, sharex=True, gridspec_kw={'height_ratios':(.85,.15)}, figsize=figsize)\n",
    "    sns.distplot(feature_var, kde=True, ax=hist_plot, kde_kws= {\"linewidth\":1.5}) \n",
    "    sns.boxplot(feature_var, ax=box_plot, linewidth = 1, width = 0.5)\n",
    "    hist_plot.set_ylabel('')    \n",
    "    hist_plot.set_xlabel('')\n",
    "    box_plot.set_xlabel('')\n",
    "    hist_plot.tick_params(labelsize=8)\n",
    "    box_plot.tick_params(labelsize=8)\n",
    "    fig.suptitle(feature_var.name, fontsize = 10)\n",
    "    hist_plot.axvline(np.mean(feature_var),color='red',linestyle='-',lw = 1.5)\n",
    "    hist_plot.axvline(np.median(feature_var),color='green',linestyle='--',lw = 1.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6CEAj3XQlEgR"
   },
   "outputs": [],
   "source": [
    "def lg_nrmse(gt, preds):\n",
    "    \"\"\"\n",
    "    @Description: Metric used in this project\n",
    "    @Params1: gt, pandas dataframe\n",
    "    @Param2: preds, pandas dataframe\n",
    "    @Return: nrmse score\n",
    "    \"\"\"\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    preds = pd.DataFrame(preds)\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14):\n",
    "        rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HfB2waRKlEdS"
   },
   "outputs": [],
   "source": [
    "def lg_individual_nrmse(gt, preds):\n",
    "    \"\"\"\n",
    "    @Description: Metric used in this project (individual)\n",
    "    @Params1: gt, pandas dataframe\n",
    "    @Param2: preds, pandas dataframe\n",
    "    @Return: nrmse score\n",
    "    \"\"\"\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    rmse = mean_squared_error(gt, preds, squared=False)\n",
    "    nrmse = rmse/np.mean(np.abs(gt))\n",
    "    return nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-zIBOcBUliiY"
   },
   "outputs": [],
   "source": [
    "def find_outlier_zscore(data, threshold = 3):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    zs = [(y - mean) / std for y in data]\n",
    "    masks = np.where(np.abs(zs) > threshold)\n",
    "    return masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QenNjbcYlkM5"
   },
   "outputs": [],
   "source": [
    "ys = ['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', \n",
    "      'Y_06', 'Y_07', 'Y_08', 'Y_09', 'Y_10', \n",
    "      'Y_11', 'Y_12', 'Y_13', 'Y_14']\n",
    "ys_bounds = [[0.2, 2], [0.2, 2.1], [0.2, 2.1], \n",
    "             [7, 19], [22, 36.5], [-19.2, 19], \n",
    "             [2.4, 4], [-29.2, -24], [-29.2, -24],\n",
    "             [-30.6, -20], [19.6, 26.6], [-29.2, -24],\n",
    "             [-29.2, -24], [-29.2, -24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FB59rtt-llsC"
   },
   "outputs": [],
   "source": [
    "seed_everything(Config.seed)\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_x = pd.read_csv('./test.csv')\n",
    "train_x, train_y = dataset_split_X_y(train_df)\n",
    "\n",
    "cols_with_zero_variance = zero_variance(train_x) # 분산이 0 (통과 여부)\n",
    "train_x = train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "test_x = test_x.drop(cols_with_zero_variance, axis = 1)\n",
    "\n",
    "train_x = train_x.drop(['X_10', 'X_11'], axis = 1) # 결측치가 많음 (결측치 = 0, 공지사항)\n",
    "test_x = test_x.drop(['X_10', 'X_11'], axis = 1)\n",
    "\n",
    "test_x = test_x.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uWxyzIilqLVx"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "  seed = 42\n",
    "  epochs = 200\n",
    "  cv=10\n",
    "  test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PhFxUQZhklLd"
   },
   "outputs": [],
   "source": [
    "def lgbm_objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'min_child_samples': int(params['min_child_samples']),\n",
    "        'colsample_bytree': '{:.5f}'.format(params['colsample_bytree']),\n",
    "        'subsample': '{:.5f}'.format(params['subsample']),\n",
    "        'min_split_gain': '{:.5f}'.format(params['min_split_gain']),\n",
    "        'scale_pos_weight': '{:.5f}'.format(params['scale_pos_weight']),\n",
    "        'reg_alpha': '{:.5f}'.format(params['reg_alpha']),\n",
    "        'reg_lambda': '{:.5f}'.format(params['reg_lambda']),\n",
    "        'learning_rate': '{:.5f}'.format(params['learning_rate']),   \n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        n_jobs = -1,\n",
    "        random_state = 1,\n",
    "        verbose = 100,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_01'], cv=Config.cv, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_01']))\n",
    "    return losses.mean()\n",
    "\n",
    "\n",
    "def xgb_objective(params):\n",
    "    params = {\n",
    "\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs = -1,\n",
    "        verbose = 100,\n",
    "        random_state = 1,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_01'], cv=Config.cv, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_01']))\n",
    "    return losses.mean()\n",
    "\n",
    "\n",
    "def cat_objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'depth': int(params['depth']),\n",
    "        'learning_rate': params['learning_rate'],   \n",
    "        'l2_leaf_reg': params['l2_leaf_reg'],\n",
    "        'max_bin': int(params['max_bin']),\n",
    "        'min_data_in_leaf': int(params['min_data_in_leaf']),\n",
    "        'random_strength': params['random_strength'],\n",
    "        'fold_len_multiplier': params['fold_len_multiplier'],\n",
    "        \n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        logging_level='Silent',\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_04'], cv=Config.cv, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_04']))\n",
    "    return losses.mean()\n",
    "\n",
    "def random_objective(params):\n",
    "    params = {\n",
    " \n",
    "    }\n",
    "\n",
    "    model = RangerForestRegressor(\n",
    "        n_jobs = -1,\n",
    "        verbose= 100\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_01'], cv=Config.cv, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_01']))\n",
    "    return losses.mean()\n",
    "\n",
    "def gradient_objective(params):\n",
    "    params = {\n",
    "\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'subsample': params['subsample'],\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'min_samples_split': int(params['min_samples_split']),\n",
    "        'min_samples_leaf': int(params['min_samples_leaf']),\n",
    "        'min_weight_fraction_leaf': params['min_weight_fraction_leaf'],\n",
    "        'min_impurity_decrease': params['min_impurity_decrease'],\n",
    "        'max_features': params['max_features'],\n",
    "        'alpha': params['alpha'],\n",
    "        'max_leaf_nodes': int(params['max_leaf_nodes']),\n",
    "        'ccp_alpha': params['ccp_alpha'],\n",
    "        \n",
    "    }\n",
    "\n",
    "    model = GradientBoostingRegressor(\n",
    "        random_state = 1,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_07'], cv=Config.cv, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_07']))\n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(losses.mean(), params))\n",
    "    \n",
    "    return losses.mean()\n",
    "\n",
    "def extra_objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'min_samples_split': int(params['min_samples_split']),\n",
    "        'min_samples_leaf': int(params['min_samples_leaf']),\n",
    "        'min_weight_fraction_leaf': params['min_weight_fraction_leaf'],\n",
    "        'max_features': params['max_features'],\n",
    "        'max_leaf_nodes': int(params['max_leaf_nodes']),\n",
    "        'min_impurity_decrease': params['min_impurity_decrease'],\n",
    "        'bootstrap': params['bootstrap'],\n",
    "        'ccp_alpha': params['ccp_alpha'],  \n",
    "    }\n",
    "\n",
    "    model = ExtraTreesRegressor(\n",
    "        n_jobs = -1,\n",
    "        verbose = 0,\n",
    "        random_state = 1,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_01'], cv=Config.cv, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_01']))\n",
    "    return losses.mean()\n",
    "\n",
    "def ngbr_objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'natural_gradient': params['natural_gradient'],\n",
    "        'col_sample': float(params['col_sample']),\n",
    "        'minibatch_frac': float(params['minibatch_frac']),\n",
    "        'tol': float(params['tol']),\n",
    "    }\n",
    "\n",
    "    model = NGBRegressor(\n",
    "        verbose = 100,\n",
    "        random_state = 1,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_01'], cv=Config.cv, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_01']))\n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(losses.mean(), params))\n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJEAijvRaiPb"
   },
   "source": [
    "## Catboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlT0GKmqaj_H",
    "outputId": "f62ed8e1-48f5-4977-d773-c5d745a4f047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/200 [00:21<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## https://catboost.ai/en/docs/concepts/parameter-tuning (참고)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m space_catboost \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m50\u001b[39m),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_len_multiplier\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_len_multiplier\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1.01\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2.5\u001b[39m)),\n\u001b[0;32m     11\u001b[0m }\n\u001b[1;32m---> 13\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspace_catboost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mcat_objective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \n\u001b[0;32m     56\u001b[0m }\n\u001b[0;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(\n\u001b[0;32m     59\u001b[0m     logging_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSilent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m     61\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m-\u001b[39m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY_04\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     64\u001b[0m losses \u001b[38;5;241m=\u001b[39m losses \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(train_y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_04\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\catboost\\core.py:5590\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5588\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5591\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5592\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5593\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\catboost\\core.py:2278\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2274\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2276\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2277\u001b[0m     plot_wrapper(plot, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2286\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2287\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mC:\\Dev\\miniconda3\\lib\\site-packages\\catboost\\core.py:1705\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1705\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4585\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4634\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## https://catboost.ai/en/docs/concepts/parameter-tuning (참고)\n",
    "space_catboost = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 500, 50),\n",
    "    'depth': hp.quniform(\"depth\", 2, 16, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 8),\n",
    "    'max_bin' : hp.quniform('max_bin', 1, 254, 1),\n",
    "    'min_data_in_leaf' : hp.quniform('min_data_in_leaf', 2, 700, 1),\n",
    "    'random_strength' : hp.loguniform('random_strength', np.log(0.005), np.log(5)),\n",
    "    'fold_len_multiplier' : hp.loguniform('fold_len_multiplier', np.log(1.01), np.log(2.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = cat_objective,\n",
    "            space = space_catboost,\n",
    "            algo = tpe.suggest,\n",
    "            verbose = 1,\n",
    "            max_evals = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33Rrmodh1OpG"
   },
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z42ZYLiqFDSV"
   },
   "source": [
    "## Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfgLLU2OFKg0"
   },
   "outputs": [],
   "source": [
    "space_extra = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1500, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 50, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 5, 50, 5),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 5, 50, 1),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0.01, 0.5),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None, 'auto']),\n",
    "    'max_leaf_nodes': hp.quniform('max_leaf_nodes', 3, 30, 1),\n",
    "    'min_impurity_decrease': hp.uniform('min_impurity_decrease', 0, 200),\n",
    "    'bootstrap':  hp.choice('bootstrap', [True, False]),\n",
    "    'ccp_alpha': hp.uniform('ccp_alpha', 0.01, 1.0),\n",
    "}\n",
    "\n",
    "best = fmin(fn = extra_objective,\n",
    "            space = space_extra,\n",
    "            algo = tpe.suggest,\n",
    "            verbose = 1,\n",
    "            max_evals = 2)\n",
    "\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['max_leaf_nodes'] = int(best['max_leaf_nodes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnfWPjbxVTvl"
   },
   "source": [
    "# RangerForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UMa6CGRVWWu"
   },
   "outputs": [],
   "source": [
    "def random_objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'mtry': int(params['mtry']),\n",
    "        'min_node_size': int(params['min_node_size']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        # 'num_random_splits': int(params['num_random_splits']),\n",
    "        'sample_fraction': params['sample_fraction'],\n",
    "        'alpha':  params['alpha'],\n",
    "        # 'split_rule' : params['split_rule'],\n",
    "    }\n",
    "\n",
    "    model = RangerForestRegressor(\n",
    "        n_jobs = -1,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_04'], cv=Config.cv, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_04']))\n",
    "    return losses.mean()\n",
    "\n",
    "space_random = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1500, 1),\n",
    "    'mtry': hp.quniform('mtry', 5, len(train_x.columns), 1),\n",
    "    'min_node_size': hp.quniform('min_node_size', 10, 200, 5),\n",
    "    'max_depth': hp.quniform('max_depth', 10, 350, 5),\n",
    "    # 'num_random_splits': hp.quniform('num_random_splits', 5, 200, 5),\n",
    "    'sample_fraction': hp.uniform('sample_fraction', 0.3, 1.0),\n",
    "    'alpha': hp.uniform('alpha', 0.3, 1.0),\n",
    "    # 'split_rule' : hp.choice('reg_lambda', ['variance', 'extratrees', 'maxstat', 'beta']),\n",
    "}\n",
    "\n",
    "best = fmin(fn = random_objective,\n",
    "            space = space_random,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 200)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzh414tCeS6k"
   },
   "source": [
    "## Gradient Boost Objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6jCCmj1ePRO"
   },
   "outputs": [],
   "source": [
    "space_gradient = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 2000, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 250, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 5, 50, 5),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 5, 50, 1),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0.01, 0.5),\n",
    "    'min_impurity_decrease': hp.uniform('min_impurity_decrease', 0, 200),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None, 'auto']),\n",
    "    'alpha': hp.uniform('alpha', 0.001, 0.999),\n",
    "    'max_leaf_nodes': hp.quniform('max_leaf_nodes', 3, 30, 1),\n",
    "    'ccp_alpha': hp.uniform('ccp_alpha', 0.01, 0.999),\n",
    "\n",
    "}\n",
    "\n",
    "best = fmin(fn = gradient_objective,\n",
    "            space = space_gradient,\n",
    "            algo = tpe.suggest,\n",
    "            verbose = 1,\n",
    "            max_evals = 200)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6_7kTkbVZJh"
   },
   "source": [
    "##LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9E4wigN9rTR"
   },
   "outputs": [],
   "source": [
    "space_lgbm = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1500, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 250, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 200, 5),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 150, 5),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.7),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 500),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 500),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = lgbm_objective,\n",
    "            space = space_lgbm,\n",
    "            algo = tpe.suggest,\n",
    "            verbose = 10,\n",
    "            max_evals = 200)\n",
    "\n",
    "print(best)\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best['num_leaves'] = int(best['num_leaves'])\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_child_samples'] = int(best['min_child_samples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoMrNNFK8u00"
   },
   "source": [
    "##NGBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97ITzGb_8ydY"
   },
   "outputs": [],
   "source": [
    "space_ngboost = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 2000, 10),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'natural_gradient': hp.choice('natural_gradient', [True, False]),\n",
    "    'col_sample': hp.quniform('col_sample', 0, 1, 0.01),\n",
    "    'minibatch_frac': hp.quniform('minibatch_frac', 0, 1, 0.01),\n",
    "    'tol': hp.uniform('tol', 1e-6, 3e-4),\n",
    "}\n",
    "\n",
    "best = fmin(fn = ngbr_objective,\n",
    "            space = space_ngboost,\n",
    "            algo = tpe.suggest,\n",
    "            verbose = 10,\n",
    "            max_evals = 100)\n",
    "\n",
    "print(best)\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best['num_leaves'] = int(best['num_leaves'])\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_child_samples'] = int(best['min_child_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlA8SXYc9_5t"
   },
   "outputs": [],
   "source": [
    "def get_stacking_base_datasets(model, train_x, train_y, col,test):\n",
    "    kf = KFold(n_splits=Config.cv, shuffle=False)\n",
    "    train_fold_pred = np.zeros((train_x.shape[0],1))\n",
    "    test_pred = np.zeros((test.shape[0],Config.cv))\n",
    "    \n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(train_x)):\n",
    "        print('Fold : ', folder_counter, ' Start')\n",
    "        X_tr = train_x.loc[train_index]\n",
    "        y_tr = train_y[col].loc[train_index]\n",
    "        X_te = train_x.loc[valid_index] \n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1) \n",
    "        test_pred[:, folder_counter] = model.predict(test) \n",
    "        \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOps13z9-StG"
   },
   "outputs": [],
   "source": [
    "model = LGBMRegressor(\n",
    "        n_jobs = -1,\n",
    "        random_state = 1,\n",
    "        verbose = 100,\n",
    "        **best\n",
    "    )\n",
    "\n",
    "\n",
    "# model 8개\n",
    "xx_train, xx_test = get_stacking_base_datasets(model, train_x, train_y, col='Y_01', test=test_x)\n",
    "yy_train, yy_test = get_stacking_base_datasets(model, train_x, train_y, col='Y_01', test=test_x)\n",
    "zz_train, zz_test = get_stacking_base_datasets(model, train_x, train_y, col='Y_01', test=test_x)\n",
    "qq_train, qq_test = get_stacking_base_datasets(model, train_x, train_y, col='Y_01', test=test_x)\n",
    "\n",
    "Stack_final_X_train = np.concatenate((xx_train,yy_train,zz_train,qq_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((xx_test,yy_test,zz_test,qq_test), axis=1)\n",
    "\n",
    "# final_model 선택해야함\n",
    "\bfinal_model.fit(Stack_final_X_train, y_train)\n",
    "stack_final = \bfinal_model.predict(Stack_final_X_test) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSh84dg_WnrV"
   },
   "outputs": [],
   "source": [
    "## col1 col2 지정\n",
    "stack_final.to_csv(f'{col1}_{col2}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FINAL.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
