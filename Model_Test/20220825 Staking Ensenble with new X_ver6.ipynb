{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88c9f79",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784827d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from lightgbm import LGBMRegressor\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ab72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69084ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split_X_y(df):    \n",
    "    \"\"\"\n",
    "    @Description: split data into features and labels\n",
    "    @Param: df, pandas dataframe with columns starting with X for features and Y for labels\n",
    "    @Return: features and labels in pandas dataframes\n",
    "    \"\"\"\n",
    "    xs = df.filter(regex='X') # Input : X Feature\n",
    "    ys = df.filter(regex='Y') # Output : Y Feature\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_variance(df):\n",
    "    \"\"\"\n",
    "    @Description: check for zero_variance\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Return: names of the columns with zero variance\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        if df[col].var() == 0:\n",
    "            result.append(col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3405de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlation(df, n=10):\n",
    "    \"\"\"\n",
    "    @Description: print out top correlated features\n",
    "    @Param1: df, pandas dataframe\n",
    "    @Param2: n, number of lines to print \n",
    "    @Return: pandas series\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    for idx1 in range(0, df.shape[1]):\n",
    "        for idx2 in range(0, idx1+1):\n",
    "            pairs.add((df.columns[idx1], df.columns[idx2]))\n",
    "    corr = df.corr().abs().unstack()\n",
    "    corr = corr.drop(labels=pairs).sort_values(ascending=False)\n",
    "    return corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8979dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg_nrmse(gt, preds):\n",
    "    \"\"\"\n",
    "    @Description: Metric used in this project\n",
    "    @Params1: gt, pandas dataframe\n",
    "    @Param2: preds, pandas dataframe\n",
    "    @Return: nrmse score\n",
    "    \"\"\"\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    preds = pd.DataFrame(preds)\n",
    "    all_nrmse = []\n",
    "    for idx in range(0,14):\n",
    "        rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f55a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_target(df):\n",
    "    \"\"\"\n",
    "    @Description: transform numeric target to binary\n",
    "    @Param1 df, pandas dataframe\n",
    "    @Param2 y_range, list of lists with min-max\n",
    "    @return labels, binary labels\n",
    "    \"\"\"\n",
    "    \n",
    "    ys = ['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', \n",
    "          'Y_06', 'Y_07', 'Y_08', 'Y_09', 'Y_10', \n",
    "          'Y_11', 'Y_12', 'Y_13', 'Y_14']\n",
    "    ys_bounds = [[0.2, 2], [0.2, 2.1], [0.2, 2.1], [7, 19], [22, 36.5], [-19.2, 19], \n",
    "                 [2.4, 4], [-29.2, -24], [-29.2, -24],[-30.6, -20], [19.6, 26.6], \n",
    "                 [-29.2, -24], [-29.2, -24], [-29.2, -24]]\n",
    "    labels = pd.DataFrame()\n",
    "    for idx in range(len(ys)):\n",
    "        y_series = ~df[ys[idx]].between(ys_bounds[idx][0], ys_bounds[idx][1], inclusive='both')\n",
    "        labels = pd.concat([labels, y_series.astype(int)], axis = 1)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c57f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_splitted_data(binary_target, col, train_x_df, train_y_df, test_size = 0.2):\n",
    "    \n",
    "    train = pd.concat([train_x_df, train_y_df[col]], axis = 1) # 학습데이터에 수치형 타겟 칼럼 추가 \n",
    "    target = binary_target[col] # 칼럼 이진 데이터 (불량 vs. 정상)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=1, test_size=test_size, stratify=target)\n",
    "    \n",
    "    # 여기서 X_test, y_test 는 이진 데이터이므로 사용하지 않음\n",
    "    # 나눠진 데이터에서 불량/정상 데이터 비율 확인 \n",
    "    print(\"학습 데이터에서의 불량/정상 Ratio : \", sum(y_train ==0) / sum(y_train))\n",
    "    print(\"테스트 데이터에서의 불량/정상 Ratio: \", sum(y_test ==0) / sum(y_test))\n",
    "    \n",
    "    train_numerical_target = X_train[col] # 나눠진 *학습* 데이터에서 수치형 데이터 다시 추출\n",
    "    train_feature = X_train.drop([col], axis = 1) # 나눠진 *학습* 데이터에서 수치형 데이터 제거\n",
    "\n",
    "    test_numerical_target = X_test[col] # 나눠진 *테스트* 데이터에서 수치형 데이터 다시 추출\n",
    "    test_feature = X_test.drop([col], axis = 1) # 나눠진 *테스트* 데이터에서 수치형 데이터 제거\n",
    "    \n",
    "    return train_feature, train_numerical_target, test_feature, test_numerical_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70733c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_x = pd.read_csv('data/test.csv')\n",
    "train_x, train_y = dataset_split_X_y(train_df)\n",
    "\n",
    "cols_with_zero_variance = zero_variance(train_x) # 분산이 0 (통과 여부)\n",
    "train_x = train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "test_x = test_x.drop(cols_with_zero_variance, axis = 1)\n",
    "\n",
    "train_x = train_x.drop(['X_10', 'X_11'], axis = 1) # 결측치가 많음 (결측치 = 0, 공지사항)\n",
    "test_x = test_x.drop(['X_10', 'X_11'], axis = 1)\n",
    "\n",
    "test_x = test_x.drop('ID', axis=1)\n",
    "y_binary_label = get_binary_target(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "533faade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터에서의 불량/정상 Ratio :  25.82895850973751\n",
      "테스트 데이터에서의 불량/정상 Ratio:  25.854237288135593\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_feature, train_target, test_feature, test_target = get_splitted_data(y_binary_label, 'Y_01', train_x, train_y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac3ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd.DataFrame(train_feature)\n",
    "train_target = pd.DataFrame(train_target)\n",
    "test_feature = pd.DataFrame(test_feature)\n",
    "test_target = pd.DataFrame(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e4c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.reset_index(inplace=True)\n",
    "train_target.reset_index(inplace=True)\n",
    "test_feature.reset_index(inplace=True)\n",
    "test_target.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad7899e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = train_feature.iloc[:, 1:]\n",
    "train_target = train_target.iloc[:, 1:]\n",
    "test_feature = test_feature.iloc[:, 1:]\n",
    "test_target = test_target.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4970246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31680</th>\n",
       "      <td>1.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31681</th>\n",
       "      <td>1.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31682</th>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31683</th>\n",
       "      <td>2.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31684</th>\n",
       "      <td>1.091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31685 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y_01\n",
       "0      1.226\n",
       "1      1.821\n",
       "2      1.532\n",
       "3      1.032\n",
       "4      1.793\n",
       "...      ...\n",
       "31680  1.355\n",
       "31681  1.775\n",
       "31682  1.392\n",
       "31683  2.013\n",
       "31684  1.091\n",
       "\n",
       "[31685 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bbfcbc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_indicator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m lst \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_indicator\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns:  \u001b[38;5;66;03m# 불량 데이터 (행) 인덱스 추출\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     lst\u001b[38;5;241m.\u001b[39mappend(df_indicator[df_indicator[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      5\u001b[0m ans\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m() \u001b[38;5;66;03m# 유니크한 인덱스\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_indicator' is not defined"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for i in df_indicator.columns:  # 불량 데이터 (행) 인덱스 추출\n",
    "    lst.append(df_indicator[df_indicator[i] == 1].index)\n",
    "    \n",
    "ans=set() # 유니크한 인덱스\n",
    "for i in lst:\n",
    "    for k in i:\n",
    "        ans.add(k)\n",
    "\n",
    "ans = list(ans)\n",
    "ans.sort()\n",
    "train_data_spec = train_df.loc[ans, :]  # 불량 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_norm = train_df.drop(train_data_spec.index) # 정상 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_norm))\n",
    "\n",
    "train_x_norm, train_y_norm = dataset_split_X_y(train_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89fcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_spec, train_y_spec = dataset_split_X_y(train_data_spec)\n",
    "print(len(train_x_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x_spec_plus_norm = pd.concat([train_x_norm, train_x_spec], axis = 0)\n",
    "new_train_y_spec_plus_norm = pd.concat([train_y_norm, train_y_spec], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ad929",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x_spec_plus_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646d538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msk1 = np.random.rand(len(train_x_norm)) < 0.8\n",
    "# msk2 = np.random.rand(len(train_x_spec)) < 0.8\n",
    "\n",
    "# tv_train_x_norm = train_x_norm[msk1]\n",
    "# tv_valid_x_norm = train_x_norm[~msk1]\n",
    "# tv_train_y_norm = train_y_norm[msk1]\n",
    "# tv_valid_y_norm = train_y_norm[~msk1]\n",
    "\n",
    "# tv_train_x_spec = train_x_spec[msk2]\n",
    "# tv_valid_x_spec = train_x_spec[~msk2]\n",
    "# tv_train_y_spec = train_y_spec[msk2]\n",
    "# tv_valid_y_spec = train_y_spec[~msk2]\n",
    "\n",
    "# tv_train_x = pd.concat([tv_train_x_norm, tv_train_x_spec], axis=0)\n",
    "# tv_valid_x = pd.concat([tv_valid_x_norm, tv_valid_x_spec], axis=0)\n",
    "# tv_train_y = pd.concat([tv_train_y_norm, tv_train_y_spec], axis=0)\n",
    "# tv_valid_y = pd.concat([tv_valid_y_norm, tv_valid_y_spec], axis=0)\n",
    "\n",
    "# tv_train_x.reset_index(inplace = True)\n",
    "# tv_valid_x.reset_index(inplace = True)\n",
    "# tv_train_y.reset_index(inplace = True)\n",
    "# tv_valid_y.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b62042",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50c724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fb1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tv_train_x))\n",
    "print(len(tv_train_y))\n",
    "print('-------------------------------------------')\n",
    "print(len(tv_valid_x))\n",
    "print(len(tv_valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babba192",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_x = tv_train_x.iloc[:, 1:]\n",
    "tv_train_y = tv_train_y.iloc[:, 1:]\n",
    "tv_valid_x = tv_valid_x.iloc[:, 1:]\n",
    "tv_valid_y = tv_valid_y.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ea767",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ddaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_with_zero_variance = zero_variance(tv_train_x) # 분산이 0 (통과 여부)\n",
    "#tv_train_x = tv_train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "#tv_valid_x = tv_train_x.drop(cols_with_zero_variance, axis = 1)\n",
    "\n",
    "tv_train_x = tv_train_x.drop(['X_10', 'X_11'], axis = 1) # 결측치가 많음 (결측치 = 0, 공지사항)\n",
    "tv_valid_x = tv_valid_x.drop(['X_10', 'X_11'], axis = 1)\n",
    "\n",
    "#tv_valid_x = tv_valid_x.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1175674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd.DataFrame(train_feature)\n",
    "train_target = pd.DataFrame(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f46e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15549</th>\n",
       "      <td>1.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26431</th>\n",
       "      <td>1.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>1.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25127</th>\n",
       "      <td>1.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>1.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19701</th>\n",
       "      <td>1.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6206</th>\n",
       "      <td>1.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28898</th>\n",
       "      <td>2.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39167</th>\n",
       "      <td>1.091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31685 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y_01\n",
       "15549  1.226\n",
       "26431  1.821\n",
       "6075   1.532\n",
       "25127  1.032\n",
       "8710   1.793\n",
       "...      ...\n",
       "19701  1.355\n",
       "6206   1.775\n",
       "5378   1.392\n",
       "28898  2.013\n",
       "39167  1.091\n",
       "\n",
       "[31685 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aa03409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'min_child_samples': int(params['min_child_samples']),\n",
    "        'colsample_bytree': '{:.5f}'.format(params['colsample_bytree']),\n",
    "        'subsample': '{:.5f}'.format(params['subsample']),\n",
    "        'min_split_gain': '{:.5f}'.format(params['min_split_gain']),\n",
    "        'scale_pos_weight': '{:.5f}'.format(params['scale_pos_weight']),\n",
    "        'reg_alpha': '{:.5f}'.format(params['reg_alpha']),\n",
    "        'reg_lambda': '{:.5f}'.format(params['reg_lambda']),\n",
    "        'learning_rate': '{:.5f}'.format(params['learning_rate']),   \n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        n_jobs = -1,\n",
    "        random_state = 1,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    losses = np.sqrt(-cross_val_score(model, train_feature, train_target, cv=10,scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_01']))\n",
    "    \n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(losses.mean(), params))\n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1598ab7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 0.25674 params {'n_estimators': 276, 'max_depth': 89, 'num_leaves': 180, 'min_child_samples': 15, 'colsample_bytree': '0.35485', 'subsample': '0.32233', 'min_split_gain': '0.45316', 'scale_pos_weight': '8.17551', 'reg_alpha': '25.15811', 'reg_lambda': '316.91357', 'learning_rate': '0.07763'}\n",
      "NRMSE Loss 0.25786 params {'n_estimators': 951, 'max_depth': 132, 'num_leaves': 80, 'min_child_samples': 35, 'colsample_bytree': '0.51974', 'subsample': '0.81896', 'min_split_gain': '0.41096', 'scale_pos_weight': '9.85671', 'reg_alpha': '70.33169', 'reg_lambda': '265.46612', 'learning_rate': '0.42966'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 1431, 'max_depth': 122, 'num_leaves': 190, 'min_child_samples': 120, 'colsample_bytree': '0.50923', 'subsample': '0.52416', 'min_split_gain': '0.37497', 'scale_pos_weight': '4.43873', 'reg_alpha': '445.48074', 'reg_lambda': '209.76655', 'learning_rate': '0.09856'}\n",
      "NRMSE Loss 0.25784 params {'n_estimators': 907, 'max_depth': 160, 'num_leaves': 185, 'min_child_samples': 80, 'colsample_bytree': '0.98335', 'subsample': '0.94048', 'min_split_gain': '0.15812', 'scale_pos_weight': '5.89904', 'reg_alpha': '96.04200', 'reg_lambda': '382.53309', 'learning_rate': '0.02236'}\n",
      "NRMSE Loss 0.25758 params {'n_estimators': 1285, 'max_depth': 197, 'num_leaves': 120, 'min_child_samples': 75, 'colsample_bytree': '0.72314', 'subsample': '0.33299', 'min_split_gain': '0.14951', 'scale_pos_weight': '6.71786', 'reg_alpha': '84.97078', 'reg_lambda': '35.94384', 'learning_rate': '0.11937'}\n",
      "NRMSE Loss 0.26143 params {'n_estimators': 289, 'max_depth': 196, 'num_leaves': 45, 'min_child_samples': 110, 'colsample_bytree': '0.52747', 'subsample': '0.48422', 'min_split_gain': '0.55679', 'scale_pos_weight': '8.19332', 'reg_alpha': '251.32415', 'reg_lambda': '196.83899', 'learning_rate': '0.10005'}\n",
      "NRMSE Loss 0.26208 params {'n_estimators': 641, 'max_depth': 201, 'num_leaves': 155, 'min_child_samples': 35, 'colsample_bytree': '0.59108', 'subsample': '0.78053', 'min_split_gain': '0.12856', 'scale_pos_weight': '7.91074', 'reg_alpha': '360.58065', 'reg_lambda': '304.78242', 'learning_rate': '0.01863'}\n",
      "NRMSE Loss 0.26269 params {'n_estimators': 1265, 'max_depth': 111, 'num_leaves': 120, 'min_child_samples': 40, 'colsample_bytree': '0.95828', 'subsample': '0.30541', 'min_split_gain': '0.01923', 'scale_pos_weight': '3.55517', 'reg_alpha': '471.03749', 'reg_lambda': '140.17892', 'learning_rate': '0.09299'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 1284, 'max_depth': 69, 'num_leaves': 145, 'min_child_samples': 70, 'colsample_bytree': '0.60549', 'subsample': '0.82742', 'min_split_gain': '0.43760', 'scale_pos_weight': '1.60675', 'reg_alpha': '429.16001', 'reg_lambda': '69.22614', 'learning_rate': '0.03767'}\n",
      "NRMSE Loss 0.26279 params {'n_estimators': 1274, 'max_depth': 149, 'num_leaves': 45, 'min_child_samples': 110, 'colsample_bytree': '0.61127', 'subsample': '0.93058', 'min_split_gain': '0.09850', 'scale_pos_weight': '2.42146', 'reg_alpha': '427.30470', 'reg_lambda': '19.01441', 'learning_rate': '0.39770'}\n",
      "NRMSE Loss 0.26022 params {'n_estimators': 1358, 'max_depth': 36, 'num_leaves': 95, 'min_child_samples': 70, 'colsample_bytree': '0.43558', 'subsample': '0.77749', 'min_split_gain': '0.15683', 'scale_pos_weight': '4.30782', 'reg_alpha': '196.34419', 'reg_lambda': '317.37219', 'learning_rate': '0.24325'}\n",
      "NRMSE Loss 0.26182 params {'n_estimators': 554, 'max_depth': 162, 'num_leaves': 105, 'min_child_samples': 145, 'colsample_bytree': '0.54631', 'subsample': '0.52911', 'min_split_gain': '0.66694', 'scale_pos_weight': '7.84113', 'reg_alpha': '287.07036', 'reg_lambda': '332.29180', 'learning_rate': '0.01378'}\n",
      "NRMSE Loss 0.26045 params {'n_estimators': 226, 'max_depth': 220, 'num_leaves': 75, 'min_child_samples': 100, 'colsample_bytree': '0.97715', 'subsample': '0.76889', 'min_split_gain': '0.26994', 'scale_pos_weight': '4.36982', 'reg_alpha': '198.89952', 'reg_lambda': '467.98110', 'learning_rate': '0.01496'}\n",
      "NRMSE Loss 0.26139 params {'n_estimators': 1487, 'max_depth': 119, 'num_leaves': 85, 'min_child_samples': 90, 'colsample_bytree': '0.52689', 'subsample': '0.97434', 'min_split_gain': '0.06824', 'scale_pos_weight': '5.13724', 'reg_alpha': '286.92912', 'reg_lambda': '127.08540', 'learning_rate': '0.26215'}\n",
      "NRMSE Loss 0.26068 params {'n_estimators': 1186, 'max_depth': 78, 'num_leaves': 60, 'min_child_samples': 145, 'colsample_bytree': '0.67118', 'subsample': '0.62175', 'min_split_gain': '0.58286', 'scale_pos_weight': '9.51848', 'reg_alpha': '196.10966', 'reg_lambda': '276.23048', 'learning_rate': '0.19143'}\n",
      "NRMSE Loss 0.25980 params {'n_estimators': 698, 'max_depth': 213, 'num_leaves': 170, 'min_child_samples': 105, 'colsample_bytree': '0.75575', 'subsample': '0.55594', 'min_split_gain': '0.20110', 'scale_pos_weight': '4.85784', 'reg_alpha': '179.34341', 'reg_lambda': '362.82068', 'learning_rate': '0.32865'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 302, 'max_depth': 57, 'num_leaves': 40, 'min_child_samples': 85, 'colsample_bytree': '0.91553', 'subsample': '0.78151', 'min_split_gain': '0.14730', 'scale_pos_weight': '2.73003', 'reg_alpha': '456.89359', 'reg_lambda': '219.04962', 'learning_rate': '0.02341'}\n",
      "NRMSE Loss 0.26153 params {'n_estimators': 1456, 'max_depth': 139, 'num_leaves': 120, 'min_child_samples': 125, 'colsample_bytree': '0.66803', 'subsample': '0.98627', 'min_split_gain': '0.12632', 'scale_pos_weight': '6.85274', 'reg_alpha': '292.28441', 'reg_lambda': '474.14898', 'learning_rate': '0.02401'}\n",
      "NRMSE Loss 0.26210 params {'n_estimators': 1318, 'max_depth': 67, 'num_leaves': 65, 'min_child_samples': 70, 'colsample_bytree': '0.75813', 'subsample': '0.90191', 'min_split_gain': '0.38689', 'scale_pos_weight': '5.07274', 'reg_alpha': '340.68563', 'reg_lambda': '407.63391', 'learning_rate': '0.04993'}\n",
      "NRMSE Loss 0.26235 params {'n_estimators': 942, 'max_depth': 164, 'num_leaves': 100, 'min_child_samples': 35, 'colsample_bytree': '0.93454', 'subsample': '0.37168', 'min_split_gain': '0.35811', 'scale_pos_weight': '6.56512', 'reg_alpha': '377.05680', 'reg_lambda': '162.00221', 'learning_rate': '0.09382'}\n",
      "NRMSE Loss 0.25617 params {'n_estimators': 448, 'max_depth': 247, 'num_leaves': 140, 'min_child_samples': 15, 'colsample_bytree': '0.31669', 'subsample': '0.41138', 'min_split_gain': '0.27661', 'scale_pos_weight': '9.05842', 'reg_alpha': '7.42624', 'reg_lambda': '66.67524', 'learning_rate': '0.15490'}\n",
      "NRMSE Loss 0.25656 params {'n_estimators': 107, 'max_depth': 247, 'num_leaves': 140, 'min_child_samples': 15, 'colsample_bytree': '0.30104', 'subsample': '0.41749', 'min_split_gain': '0.25797', 'scale_pos_weight': '8.80428', 'reg_alpha': '24.90175', 'reg_lambda': '99.56509', 'learning_rate': '0.16235'}\n",
      "NRMSE Loss 0.25624 params {'n_estimators': 469, 'max_depth': 240, 'num_leaves': 145, 'min_child_samples': 15, 'colsample_bytree': '0.30115', 'subsample': '0.41273', 'min_split_gain': '0.28978', 'scale_pos_weight': '9.35911', 'reg_alpha': '11.61840', 'reg_lambda': '77.24608', 'learning_rate': '0.15803'}\n",
      "NRMSE Loss 0.25919 params {'n_estimators': 459, 'max_depth': 247, 'num_leaves': 165, 'min_child_samples': 50, 'colsample_bytree': '0.30852', 'subsample': '0.43784', 'min_split_gain': '0.29824', 'scale_pos_weight': '9.34207', 'reg_alpha': '137.74138', 'reg_lambda': '7.20783', 'learning_rate': '0.05286'}\n",
      "NRMSE Loss 0.25628 params {'n_estimators': 432, 'max_depth': 231, 'num_leaves': 140, 'min_child_samples': 10, 'colsample_bytree': '0.41288', 'subsample': '0.67207', 'min_split_gain': '0.48702', 'scale_pos_weight': '9.95043', 'reg_alpha': '5.56888', 'reg_lambda': '66.35430', 'learning_rate': '0.15022'}\n",
      "NRMSE Loss 0.25719 params {'n_estimators': 131, 'max_depth': 182, 'num_leaves': 130, 'min_child_samples': 50, 'colsample_bytree': '0.38386', 'subsample': '0.64670', 'min_split_gain': '0.30233', 'scale_pos_weight': '8.69592', 'reg_alpha': '51.89424', 'reg_lambda': '84.35653', 'learning_rate': '0.21765'}\n",
      "NRMSE Loss 0.25861 params {'n_estimators': 752, 'max_depth': 249, 'num_leaves': 200, 'min_child_samples': 25, 'colsample_bytree': '0.86086', 'subsample': '0.39382', 'min_split_gain': '0.22331', 'scale_pos_weight': '7.32407', 'reg_alpha': '127.81895', 'reg_lambda': '175.75114', 'learning_rate': '0.13651'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 0.25921 params {'n_estimators': 424, 'max_depth': 12, 'num_leaves': 160, 'min_child_samples': 55, 'colsample_bytree': '0.45721', 'subsample': '0.46986', 'min_split_gain': '0.32645', 'scale_pos_weight': '9.11140', 'reg_alpha': '140.40273', 'reg_lambda': '45.14901', 'learning_rate': '0.33089'}\n",
      "NRMSE Loss 0.25593 params {'n_estimators': 572, 'max_depth': 231, 'num_leaves': 175, 'min_child_samples': 20, 'colsample_bytree': '0.33106', 'subsample': '0.58967', 'min_split_gain': '0.46315', 'scale_pos_weight': '6.18212', 'reg_alpha': '0.40427', 'reg_lambda': '116.06658', 'learning_rate': '0.06731'}\n",
      "NRMSE Loss 0.25729 params {'n_estimators': 845, 'max_depth': 100, 'num_leaves': 175, 'min_child_samples': 25, 'colsample_bytree': '0.36953', 'subsample': '0.58702', 'min_split_gain': '0.47697', 'scale_pos_weight': '5.93219', 'reg_alpha': '46.60323', 'reg_lambda': '118.62368', 'learning_rate': '0.06547'}\n",
      "NRMSE Loss 0.25872 params {'n_estimators': 599, 'max_depth': 179, 'num_leaves': 200, 'min_child_samples': 25, 'colsample_bytree': '0.33999', 'subsample': '0.68562', 'min_split_gain': '0.53555', 'scale_pos_weight': '5.92377', 'reg_alpha': '101.73337', 'reg_lambda': '239.53219', 'learning_rate': '0.03392'}\n",
      "NRMSE Loss 0.25750 params {'n_estimators': 1051, 'max_depth': 225, 'num_leaves': 180, 'min_child_samples': 10, 'colsample_bytree': '0.45003', 'subsample': '0.71911', 'min_split_gain': '0.67680', 'scale_pos_weight': '7.35105', 'reg_alpha': '45.70561', 'reg_lambda': '3.92625', 'learning_rate': '0.01040'}\n",
      "NRMSE Loss 0.25656 params {'n_estimators': 1054, 'max_depth': 181, 'num_leaves': 20, 'min_child_samples': 60, 'colsample_bytree': '0.33804', 'subsample': '0.60517', 'min_split_gain': '0.61669', 'scale_pos_weight': '3.61940', 'reg_alpha': '10.16790', 'reg_lambda': '158.02095', 'learning_rate': '0.06492'}\n",
      "NRMSE Loss 0.25784 params {'n_estimators': 359, 'max_depth': 213, 'num_leaves': 190, 'min_child_samples': 20, 'colsample_bytree': '0.39243', 'subsample': '0.48150', 'min_split_gain': '0.42962', 'scale_pos_weight': '8.40178', 'reg_alpha': '70.24145', 'reg_lambda': '105.43852', 'learning_rate': '0.03426'}\n",
      "NRMSE Loss 0.26082 params {'n_estimators': 177, 'max_depth': 206, 'num_leaves': 155, 'min_child_samples': 40, 'colsample_bytree': '0.48238', 'subsample': '0.33789', 'min_split_gain': '0.22306', 'scale_pos_weight': '6.37182', 'reg_alpha': '232.26536', 'reg_lambda': '188.72295', 'learning_rate': '0.49984'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 557, 'max_depth': 237, 'num_leaves': 130, 'min_child_samples': 45, 'colsample_bytree': '0.85429', 'subsample': '0.54017', 'min_split_gain': '0.51269', 'scale_pos_weight': '7.35539', 'reg_alpha': '496.91236', 'reg_lambda': '31.75572', 'learning_rate': '0.08044'}\n",
      "NRMSE Loss 0.25888 params {'n_estimators': 705, 'max_depth': 147, 'num_leaves': 190, 'min_child_samples': 130, 'colsample_bytree': '0.33982', 'subsample': '0.44849', 'min_split_gain': '0.61388', 'scale_pos_weight': '9.95730', 'reg_alpha': '105.80309', 'reg_lambda': '260.49983', 'learning_rate': '0.11281'}\n",
      "NRMSE Loss 0.25878 params {'n_estimators': 805, 'max_depth': 195, 'num_leaves': 115, 'min_child_samples': 30, 'colsample_bytree': '0.55715', 'subsample': '0.35431', 'min_split_gain': '0.00064', 'scale_pos_weight': '1.41841', 'reg_alpha': '170.14943', 'reg_lambda': '218.16209', 'learning_rate': '0.04344'}\n",
      "NRMSE Loss 0.25782 params {'n_estimators': 1020, 'max_depth': 174, 'num_leaves': 130, 'min_child_samples': 60, 'colsample_bytree': '0.48913', 'subsample': '0.50637', 'min_split_gain': '0.40237', 'scale_pos_weight': '3.66927', 'reg_alpha': '72.36771', 'reg_lambda': '42.24583', 'learning_rate': '0.07974'}\n",
      "NRMSE Loss 0.26119 params {'n_estimators': 362, 'max_depth': 130, 'num_leaves': 155, 'min_child_samples': 10, 'colsample_bytree': '0.70876', 'subsample': '0.56183', 'min_split_gain': '0.34585', 'scale_pos_weight': '5.56537', 'reg_alpha': '245.49579', 'reg_lambda': '286.73312', 'learning_rate': '0.11930'}\n",
      "NRMSE Loss 0.25562 params {'n_estimators': 518, 'max_depth': 189, 'num_leaves': 175, 'min_child_samples': 35, 'colsample_bytree': '0.56942', 'subsample': '0.85676', 'min_split_gain': '0.45945', 'scale_pos_weight': '7.94228', 'reg_alpha': '0.25488', 'reg_lambda': '141.09174', 'learning_rate': '0.05750'}\n",
      "NRMSE Loss 0.25972 params {'n_estimators': 852, 'max_depth': 194, 'num_leaves': 200, 'min_child_samples': 35, 'colsample_bytree': '0.63717', 'subsample': '0.86316', 'min_split_gain': '0.47338', 'scale_pos_weight': '6.96221', 'reg_alpha': '152.64482', 'reg_lambda': '135.57553', 'learning_rate': '0.05471'}\n",
      "NRMSE Loss 0.25913 params {'n_estimators': 547, 'max_depth': 170, 'num_leaves': 180, 'min_child_samples': 60, 'colsample_bytree': '0.80893', 'subsample': '0.72713', 'min_split_gain': '0.56822', 'scale_pos_weight': '8.00243', 'reg_alpha': '121.65367', 'reg_lambda': '233.83548', 'learning_rate': '0.03107'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 657, 'max_depth': 101, 'num_leaves': 170, 'min_child_samples': 80, 'colsample_bytree': '0.57146', 'subsample': '0.82250', 'min_split_gain': '0.63608', 'scale_pos_weight': '7.63103', 'reg_alpha': '398.59510', 'reg_lambda': '202.30111', 'learning_rate': '0.02630'}\n",
      "NRMSE Loss 0.26209 params {'n_estimators': 254, 'max_depth': 151, 'num_leaves': 90, 'min_child_samples': 95, 'colsample_bytree': '0.70760', 'subsample': '0.86949', 'min_split_gain': '0.51212', 'scale_pos_weight': '6.16725', 'reg_alpha': '331.84747', 'reg_lambda': '160.07673', 'learning_rate': '0.01752'}\n",
      "NRMSE Loss 0.26098 params {'n_estimators': 1147, 'max_depth': 187, 'num_leaves': 195, 'min_child_samples': 40, 'colsample_bytree': '0.61668', 'subsample': '0.94008', 'min_split_gain': '0.44065', 'scale_pos_weight': '5.56650', 'reg_alpha': '221.50095', 'reg_lambda': '145.15801', 'learning_rate': '0.01204'}\n",
      "NRMSE Loss 0.25842 params {'n_estimators': 349, 'max_depth': 221, 'num_leaves': 185, 'min_child_samples': 65, 'colsample_bytree': '0.41737', 'subsample': '0.72700', 'min_split_gain': '0.69678', 'scale_pos_weight': '2.55392', 'reg_alpha': '79.45347', 'reg_lambda': '345.88384', 'learning_rate': '0.04312'}\n",
      "NRMSE Loss 0.25713 params {'n_estimators': 514, 'max_depth': 204, 'num_leaves': 110, 'min_child_samples': 75, 'colsample_bytree': '0.51550', 'subsample': '0.63445', 'min_split_gain': '0.53502', 'scale_pos_weight': '4.03344', 'reg_alpha': '36.88422', 'reg_lambda': '417.11446', 'learning_rate': '0.01880'}\n",
      "NRMSE Loss 0.26148 params {'n_estimators': 760, 'max_depth': 152, 'num_leaves': 160, 'min_child_samples': 50, 'colsample_bytree': '0.58323', 'subsample': '0.79770', 'min_split_gain': '0.41456', 'scale_pos_weight': '3.17879', 'reg_alpha': '264.24702', 'reg_lambda': '295.27824', 'learning_rate': '0.06647'}\n",
      "NRMSE Loss 0.25975 params {'n_estimators': 622, 'max_depth': 211, 'num_leaves': 150, 'min_child_samples': 30, 'colsample_bytree': '0.79236', 'subsample': '0.75379', 'min_split_gain': '0.38042', 'scale_pos_weight': '4.71097', 'reg_alpha': '160.94329', 'reg_lambda': '177.26448', 'learning_rate': '0.02846'}\n",
      "NRMSE Loss 0.25782 params {'n_estimators': 171, 'max_depth': 121, 'num_leaves': 75, 'min_child_samples': 20, 'colsample_bytree': '0.65339', 'subsample': '0.67067', 'min_split_gain': '0.58669', 'scale_pos_weight': '8.18479', 'reg_alpha': '60.86817', 'reg_lambda': '498.96407', 'learning_rate': '0.04569'}\n",
      "NRMSE Loss 0.26181 params {'n_estimators': 895, 'max_depth': 40, 'num_leaves': 165, 'min_child_samples': 115, 'colsample_bytree': '0.48921', 'subsample': '0.99917', 'min_split_gain': '0.32261', 'scale_pos_weight': '1.93777', 'reg_alpha': '312.89808', 'reg_lambda': '108.17586', 'learning_rate': '0.18652'}\n",
      "NRMSE Loss 0.25837 params {'n_estimators': 985, 'max_depth': 233, 'num_leaves': 35, 'min_child_samples': 85, 'colsample_bytree': '0.53541', 'subsample': '0.86156', 'min_split_gain': '0.45291', 'scale_pos_weight': '8.50677', 'reg_alpha': '97.49984', 'reg_lambda': '256.41789', 'learning_rate': '0.10338'}\n",
      "NRMSE Loss 0.25584 params {'n_estimators': 326, 'max_depth': 139, 'num_leaves': 125, 'min_child_samples': 45, 'colsample_bytree': '0.74831', 'subsample': '0.69714', 'min_split_gain': '0.07445', 'scale_pos_weight': '5.26186', 'reg_alpha': '25.41959', 'reg_lambda': '313.63967', 'learning_rate': '0.02071'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 0.25645 params {'n_estimators': 206, 'max_depth': 111, 'num_leaves': 100, 'min_child_samples': 45, 'colsample_bytree': '0.74923', 'subsample': '0.90297', 'min_split_gain': '0.07020', 'scale_pos_weight': '5.23307', 'reg_alpha': '23.60080', 'reg_lambda': '415.52243', 'learning_rate': '0.01526'}\n",
      "NRMSE Loss 0.25999 params {'n_estimators': 288, 'max_depth': 86, 'num_leaves': 135, 'min_child_samples': 70, 'colsample_bytree': '0.84913', 'subsample': '0.97070', 'min_split_gain': '0.02697', 'scale_pos_weight': '3.99594', 'reg_alpha': '209.11159', 'reg_lambda': '317.12871', 'learning_rate': '0.01001'}\n",
      "NRMSE Loss 0.26134 params {'n_estimators': 502, 'max_depth': 132, 'num_leaves': 125, 'min_child_samples': 55, 'colsample_bytree': '0.89778', 'subsample': '0.84131', 'min_split_gain': '0.18718', 'scale_pos_weight': '2.96998', 'reg_alpha': '271.11133', 'reg_lambda': '452.60973', 'learning_rate': '0.01998'}\n",
      "NRMSE Loss 0.25812 params {'n_estimators': 391, 'max_depth': 8, 'num_leaves': 60, 'min_child_samples': 40, 'colsample_bytree': '0.68336', 'subsample': '0.89900', 'min_split_gain': '0.09566', 'scale_pos_weight': '4.54723', 'reg_alpha': '117.57501', 'reg_lambda': '371.93189', 'learning_rate': '0.01188'}\n",
      "NRMSE Loss 0.25946 params {'n_estimators': 674, 'max_depth': 139, 'num_leaves': 85, 'min_child_samples': 75, 'colsample_bytree': '0.79853', 'subsample': '0.76169', 'min_split_gain': '0.04015', 'scale_pos_weight': '1.99564', 'reg_alpha': '185.91259', 'reg_lambda': '334.01688', 'learning_rate': '0.02286'}\n",
      "NRMSE Loss 0.25929 params {'n_estimators': 103, 'max_depth': 162, 'num_leaves': 75, 'min_child_samples': 65, 'colsample_bytree': '0.73161', 'subsample': '0.69574', 'min_split_gain': '0.25600', 'scale_pos_weight': '6.70776', 'reg_alpha': '86.66675', 'reg_lambda': '397.64307', 'learning_rate': '0.01599'}\n",
      "NRMSE Loss 0.26244 params {'n_estimators': 308, 'max_depth': 55, 'num_leaves': 115, 'min_child_samples': 100, 'colsample_bytree': '0.62310', 'subsample': '0.80151', 'min_split_gain': '0.17291', 'scale_pos_weight': '9.67797', 'reg_alpha': '394.50287', 'reg_lambda': '438.43450', 'learning_rate': '0.03921'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 730, 'max_depth': 113, 'num_leaves': 105, 'min_child_samples': 135, 'colsample_bytree': '0.96097', 'subsample': '0.30060', 'min_split_gain': '0.35460', 'scale_pos_weight': '7.04265', 'reg_alpha': '499.24727', 'reg_lambda': '357.56393', 'learning_rate': '0.05470'}\n",
      "NRMSE Loss 0.25694 params {'n_estimators': 247, 'max_depth': 94, 'num_leaves': 145, 'min_child_samples': 30, 'colsample_bytree': '0.77216', 'subsample': '0.92218', 'min_split_gain': '0.49333', 'scale_pos_weight': '5.35941', 'reg_alpha': '35.47003', 'reg_lambda': '281.92386', 'learning_rate': '0.02113'}\n",
      "NRMSE Loss 0.25879 params {'n_estimators': 503, 'max_depth': 79, 'num_leaves': 65, 'min_child_samples': 45, 'colsample_bytree': '0.64641', 'subsample': '0.95135', 'min_split_gain': '0.12143', 'scale_pos_weight': '7.80266', 'reg_alpha': '143.92136', 'reg_lambda': '310.03577', 'learning_rate': '0.08632'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 167, 'max_depth': 20, 'num_leaves': 55, 'min_child_samples': 90, 'colsample_bytree': '0.67858', 'subsample': '0.74725', 'min_split_gain': '0.20743', 'scale_pos_weight': '4.16031', 'reg_alpha': '430.20919', 'reg_lambda': '493.66980', 'learning_rate': '0.01358'}\n",
      "NRMSE Loss 0.25588 params {'n_estimators': 598, 'max_depth': 188, 'num_leaves': 175, 'min_child_samples': 20, 'colsample_bytree': '0.88254', 'subsample': '0.59019', 'min_split_gain': '0.40153', 'scale_pos_weight': '6.37635', 'reg_alpha': '4.28360', 'reg_lambda': '243.55289', 'learning_rate': '0.07134'}\n",
      "NRMSE Loss 0.25630 params {'n_estimators': 611, 'max_depth': 172, 'num_leaves': 150, 'min_child_samples': 35, 'colsample_bytree': '0.89831', 'subsample': '0.60989', 'min_split_gain': '0.33091', 'scale_pos_weight': '5.81736', 'reg_alpha': '21.88217', 'reg_lambda': '231.02679', 'learning_rate': '0.03702'}\n",
      "NRMSE Loss 0.25557 params {'n_estimators': 784, 'max_depth': 190, 'num_leaves': 170, 'min_child_samples': 15, 'colsample_bytree': '0.87111', 'subsample': '0.51213', 'min_split_gain': '0.23913', 'scale_pos_weight': '4.99730', 'reg_alpha': '1.10167', 'reg_lambda': '192.26942', 'learning_rate': '0.13345'}\n",
      "NRMSE Loss 0.25705 params {'n_estimators': 1167, 'max_depth': 140, 'num_leaves': 185, 'min_child_samples': 15, 'colsample_bytree': '0.93064', 'subsample': '0.51241', 'min_split_gain': '0.24383', 'scale_pos_weight': '4.58546', 'reg_alpha': '54.96845', 'reg_lambda': '271.08886', 'learning_rate': '0.29112'}\n",
      "NRMSE Loss 0.25785 params {'n_estimators': 781, 'max_depth': 165, 'num_leaves': 165, 'min_child_samples': 55, 'colsample_bytree': '0.99171', 'subsample': '0.56166', 'min_split_gain': '0.05792', 'scale_pos_weight': '1.07475', 'reg_alpha': '113.41134', 'reg_lambda': '188.37586', 'learning_rate': '0.13205'}\n",
      "NRMSE Loss 0.25852 params {'n_estimators': 936, 'max_depth': 126, 'num_leaves': 135, 'min_child_samples': 10, 'colsample_bytree': '0.84340', 'subsample': '0.65660', 'min_split_gain': '0.09368', 'scale_pos_weight': '5.09208', 'reg_alpha': '0.69650', 'reg_lambda': '300.51976', 'learning_rate': '0.40914'}\n",
      "NRMSE Loss 0.25640 params {'n_estimators': 846, 'max_depth': 154, 'num_leaves': 120, 'min_child_samples': 25, 'colsample_bytree': '0.77759', 'subsample': '0.44421', 'min_split_gain': '0.13525', 'scale_pos_weight': '3.38055', 'reg_alpha': '36.34772', 'reg_lambda': '84.32620', 'learning_rate': '0.20779'}\n",
      "NRMSE Loss 0.25725 params {'n_estimators': 1110, 'max_depth': 198, 'num_leaves': 195, 'min_child_samples': 50, 'colsample_bytree': '0.82389', 'subsample': '0.49974', 'min_split_gain': '0.16526', 'scale_pos_weight': '4.71907', 'reg_alpha': '66.99056', 'reg_lambda': '218.47778', 'learning_rate': '0.18150'}\n",
      "NRMSE Loss 0.25775 params {'n_estimators': 684, 'max_depth': 157, 'num_leaves': 170, 'min_child_samples': 15, 'colsample_bytree': '0.70002', 'subsample': '0.70631', 'min_split_gain': '0.23440', 'scale_pos_weight': '4.95020', 'reg_alpha': '87.12112', 'reg_lambda': '208.76647', 'learning_rate': '0.25098'}\n",
      "NRMSE Loss 0.25915 params {'n_estimators': 413, 'max_depth': 146, 'num_leaves': 150, 'min_child_samples': 30, 'colsample_bytree': '0.72842', 'subsample': '0.53832', 'min_split_gain': '0.37240', 'scale_pos_weight': '4.29731', 'reg_alpha': '135.22936', 'reg_lambda': '56.69422', 'learning_rate': '0.06017'}\n",
      "NRMSE Loss 0.25572 params {'n_estimators': 483, 'max_depth': 191, 'num_leaves': 160, 'min_child_samples': 35, 'colsample_bytree': '0.60251', 'subsample': '0.39098', 'min_split_gain': '0.00391', 'scale_pos_weight': '5.63362', 'reg_alpha': '21.54178', 'reg_lambda': '144.80158', 'learning_rate': '0.09829'}\n",
      "NRMSE Loss 0.25617 params {'n_estimators': 802, 'max_depth': 225, 'num_leaves': 160, 'min_child_samples': 35, 'colsample_bytree': '0.59488', 'subsample': '0.35503', 'min_split_gain': '0.29062', 'scale_pos_weight': '7.08404', 'reg_alpha': '17.33079', 'reg_lambda': '142.42432', 'learning_rate': '0.10833'}\n",
      "NRMSE Loss 0.25734 params {'n_estimators': 1396, 'max_depth': 189, 'num_leaves': 185, 'min_child_samples': 25, 'colsample_bytree': '0.55611', 'subsample': '0.47570', 'min_split_gain': '0.54241', 'scale_pos_weight': '8.83693', 'reg_alpha': '47.58891', 'reg_lambda': '98.35024', 'learning_rate': '0.13357'}\n",
      "NRMSE Loss 0.25803 params {'n_estimators': 894, 'max_depth': 209, 'num_leaves': 195, 'min_child_samples': 65, 'colsample_bytree': '0.57949', 'subsample': '0.42520', 'min_split_gain': '0.31029', 'scale_pos_weight': '5.73974', 'reg_alpha': '91.35367', 'reg_lambda': '128.10547', 'learning_rate': '0.09745'}\n",
      "NRMSE Loss 0.25979 params {'n_estimators': 1242, 'max_depth': 243, 'num_leaves': 175, 'min_child_samples': 20, 'colsample_bytree': '0.45178', 'subsample': '0.37081', 'min_split_gain': '0.26925', 'scale_pos_weight': '7.57295', 'reg_alpha': '170.42883', 'reg_lambda': '16.98978', 'learning_rate': '0.33753'}\n",
      "NRMSE Loss 0.25790 params {'n_estimators': 464, 'max_depth': 216, 'num_leaves': 155, 'min_child_samples': 40, 'colsample_bytree': '0.47332', 'subsample': '0.31900', 'min_split_gain': '0.42141', 'scale_pos_weight': '6.45385', 'reg_alpha': '75.11965', 'reg_lambda': '183.75148', 'learning_rate': '0.09073'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 0.25893 params {'n_estimators': 719, 'max_depth': 179, 'num_leaves': 140, 'min_child_samples': 10, 'colsample_bytree': '0.42722', 'subsample': '0.40719', 'min_split_gain': '0.59831', 'scale_pos_weight': '3.80663', 'reg_alpha': '108.14912', 'reg_lambda': '168.63745', 'learning_rate': '0.16927'}\n",
      "NRMSE Loss 0.25660 params {'n_estimators': 638, 'max_depth': 201, 'num_leaves': 180, 'min_child_samples': 30, 'colsample_bytree': '0.49842', 'subsample': '0.45034', 'min_split_gain': '0.01645', 'scale_pos_weight': '6.81136', 'reg_alpha': '61.27422', 'reg_lambda': '153.79570', 'learning_rate': '0.22171'}\n",
      "NRMSE Loss 0.25570 params {'n_estimators': 1088, 'max_depth': 168, 'num_leaves': 170, 'min_child_samples': 15, 'colsample_bytree': '0.60066', 'subsample': '0.38337', 'min_split_gain': '0.44531', 'scale_pos_weight': '6.10485', 'reg_alpha': '0.29239', 'reg_lambda': '198.70901', 'learning_rate': '0.07231'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 1097, 'max_depth': 184, 'num_leaves': 165, 'min_child_samples': 15, 'colsample_bytree': '0.52400', 'subsample': '0.57455', 'min_split_gain': '0.45470', 'scale_pos_weight': '7.19204', 'reg_alpha': '483.42050', 'reg_lambda': '197.52204', 'learning_rate': '0.04748'}\n",
      "NRMSE Loss 0.26224 params {'n_estimators': 1206, 'max_depth': 167, 'num_leaves': 200, 'min_child_samples': 110, 'colsample_bytree': '0.54193', 'subsample': '0.33856', 'min_split_gain': '0.51518', 'scale_pos_weight': '6.07291', 'reg_alpha': '352.60557', 'reg_lambda': '227.91869', 'learning_rate': '0.07439'}\n",
      "NRMSE Loss 0.26193 params {'n_estimators': 1323, 'max_depth': 174, 'num_leaves': 190, 'min_child_samples': 10, 'colsample_bytree': '0.63847', 'subsample': '0.46523', 'min_split_gain': '0.65431', 'scale_pos_weight': '8.32373', 'reg_alpha': '302.27645', 'reg_lambda': '252.27733', 'learning_rate': '0.05951'}\n",
      "NRMSE Loss 0.25693 params {'n_estimators': 1025, 'max_depth': 158, 'num_leaves': 180, 'min_child_samples': 25, 'colsample_bytree': '0.56423', 'subsample': '0.31880', 'min_split_gain': '0.49682', 'scale_pos_weight': '6.61438', 'reg_alpha': '33.41153', 'reg_lambda': '126.55862', 'learning_rate': '0.11875'}\n",
      "NRMSE Loss 0.25923 params {'n_estimators': 940, 'max_depth': 221, 'num_leaves': 170, 'min_child_samples': 120, 'colsample_bytree': '0.62851', 'subsample': '0.52125', 'min_split_gain': '0.56385', 'scale_pos_weight': '9.11904', 'reg_alpha': '124.50569', 'reg_lambda': '267.14578', 'learning_rate': '0.14720'}\n",
      "NRMSE Loss 0.25951 params {'n_estimators': 1487, 'max_depth': 235, 'num_leaves': 25, 'min_child_samples': 20, 'colsample_bytree': '0.69579', 'subsample': '0.49191', 'min_split_gain': '0.39419', 'scale_pos_weight': '8.63370', 'reg_alpha': '151.93938', 'reg_lambda': '55.18571', 'learning_rate': '0.08144'}\n",
      "NRMSE Loss 0.25692 params {'n_estimators': 1002, 'max_depth': 228, 'num_leaves': 145, 'min_child_samples': 50, 'colsample_bytree': '0.39101', 'subsample': '0.63142', 'min_split_gain': '0.34096', 'scale_pos_weight': '8.04269', 'reg_alpha': '10.56899', 'reg_lambda': '92.62800', 'learning_rate': '0.49594'}\n",
      "NRMSE Loss 0.26075 params {'n_estimators': 871, 'max_depth': 145, 'num_leaves': 135, 'min_child_samples': 80, 'colsample_bytree': '0.50162', 'subsample': '0.38632', 'min_split_gain': '0.36841', 'scale_pos_weight': '7.69170', 'reg_alpha': '207.20234', 'reg_lambda': '208.33296', 'learning_rate': '0.02885'}\n",
      "NRMSE Loss 0.25674 params {'n_estimators': 1083, 'max_depth': 115, 'num_leaves': 195, 'min_child_samples': 15, 'colsample_bytree': '0.66591', 'subsample': '0.42881', 'min_split_gain': '0.20686', 'scale_pos_weight': '7.43538', 'reg_alpha': '0.83484', 'reg_lambda': '113.74315', 'learning_rate': '0.28200'}\n",
      "NRMSE Loss 0.26044 params {'n_estimators': 977, 'max_depth': 104, 'num_leaves': 175, 'min_child_samples': 30, 'colsample_bytree': '0.66023', 'subsample': '0.54399', 'min_split_gain': '0.43717', 'scale_pos_weight': '6.07165', 'reg_alpha': '186.04918', 'reg_lambda': '74.29994', 'learning_rate': '0.02513'}\n",
      "NRMSE Loss 0.26109 params {'n_estimators': 1397, 'max_depth': 206, 'num_leaves': 125, 'min_child_samples': 140, 'colsample_bytree': '0.37528', 'subsample': '0.45594', 'min_split_gain': '0.31439', 'scale_pos_weight': '9.68773', 'reg_alpha': '236.33541', 'reg_lambda': '165.34632', 'learning_rate': '0.05796'}\n",
      "NRMSE Loss 0.25722 params {'n_estimators': 1209, 'max_depth': 197, 'num_leaves': 185, 'min_child_samples': 150, 'colsample_bytree': '0.82832', 'subsample': '0.84347', 'min_split_gain': '0.47662', 'scale_pos_weight': '5.37662', 'reg_alpha': '44.30007', 'reg_lambda': '328.12679', 'learning_rate': '0.03282'}\n",
      "NRMSE Loss 0.26290 params {'n_estimators': 755, 'max_depth': 133, 'num_leaves': 150, 'min_child_samples': 55, 'colsample_bytree': '0.87293', 'subsample': '0.36834', 'min_split_gain': '0.52048', 'scale_pos_weight': '2.87705', 'reg_alpha': '456.26349', 'reg_lambda': '24.12007', 'learning_rate': '0.05100'}\n",
      "NRMSE Loss 0.25829 params {'n_estimators': 1129, 'max_depth': 180, 'num_leaves': 190, 'min_child_samples': 85, 'colsample_bytree': '0.46785', 'subsample': '0.59919', 'min_split_gain': '0.27379', 'scale_pos_weight': '6.26468', 'reg_alpha': '102.02863', 'reg_lambda': '178.39385', 'learning_rate': '0.03870'}\n",
      "NRMSE Loss 0.26148 params {'n_estimators': 569, 'max_depth': 175, 'num_leaves': 155, 'min_child_samples': 40, 'colsample_bytree': '0.43692', 'subsample': '0.78965', 'min_split_gain': '0.41210', 'scale_pos_weight': '2.34144', 'reg_alpha': '263.62050', 'reg_lambda': '246.41228', 'learning_rate': '0.12475'}\n",
      "NRMSE Loss 0.25786 params {'n_estimators': 1061, 'max_depth': 217, 'num_leaves': 110, 'min_child_samples': 20, 'colsample_bytree': '0.61283', 'subsample': '0.62020', 'min_split_gain': '0.38508', 'scale_pos_weight': '3.47026', 'reg_alpha': '78.80967', 'reg_lambda': '197.34276', 'learning_rate': '0.16838'}\n",
      "NRMSE Loss 0.26196 params {'n_estimators': 812, 'max_depth': 166, 'num_leaves': 95, 'min_child_samples': 60, 'colsample_bytree': '0.71789', 'subsample': '0.40180', 'min_split_gain': '0.54834', 'scale_pos_weight': '3.87330', 'reg_alpha': '323.72527', 'reg_lambda': '151.61687', 'learning_rate': '0.36869'}\n",
      "NRMSE Loss 0.25759 params {'n_estimators': 1261, 'max_depth': 250, 'num_leaves': 140, 'min_child_samples': 45, 'colsample_bytree': '0.94468', 'subsample': '0.57604', 'min_split_gain': '0.62961', 'scale_pos_weight': '9.40426', 'reg_alpha': '54.09040', 'reg_lambda': '288.59763', 'learning_rate': '0.14116'}\n",
      "NRMSE Loss 0.25939 params {'n_estimators': 1312, 'max_depth': 126, 'num_leaves': 115, 'min_child_samples': 100, 'colsample_bytree': '0.51129', 'subsample': '0.65099', 'min_split_gain': '0.58983', 'scale_pos_weight': '6.85535', 'reg_alpha': '129.05480', 'reg_lambda': '132.88829', 'learning_rate': '0.08820'}\n",
      "NRMSE Loss 0.25656 params {'n_estimators': 822, 'max_depth': 239, 'num_leaves': 170, 'min_child_samples': 35, 'colsample_bytree': '0.68829', 'subsample': '0.73965', 'min_split_gain': '0.36004', 'scale_pos_weight': '7.89753', 'reg_alpha': '29.42780', 'reg_lambda': '221.77864', 'learning_rate': '0.04201'}\n",
      "NRMSE Loss 0.25596 params {'n_estimators': 519, 'max_depth': 202, 'num_leaves': 160, 'min_child_samples': 70, 'colsample_bytree': '0.36009', 'subsample': '0.67877', 'min_split_gain': '0.18733', 'scale_pos_weight': '8.94301', 'reg_alpha': '13.15868', 'reg_lambda': '87.93154', 'learning_rate': '0.10770'}\n",
      "NRMSE Loss 0.25782 params {'n_estimators': 915, 'max_depth': 194, 'num_leaves': 130, 'min_child_samples': 25, 'colsample_bytree': '0.54853', 'subsample': '0.30016', 'min_split_gain': '0.52806', 'scale_pos_weight': '4.79817', 'reg_alpha': '67.06606', 'reg_lambda': '236.19872', 'learning_rate': '0.07375'}\n",
      "NRMSE Loss 0.26082 params {'n_estimators': 870, 'max_depth': 143, 'num_leaves': 180, 'min_child_samples': 15, 'colsample_bytree': '0.76230', 'subsample': '0.99411', 'min_split_gain': '0.33268', 'scale_pos_weight': '5.01588', 'reg_alpha': '219.91729', 'reg_lambda': '121.75183', 'learning_rate': '0.06594'}\n",
      "NRMSE Loss 0.26246 params {'n_estimators': 1448, 'max_depth': 160, 'num_leaves': 165, 'min_child_samples': 40, 'colsample_bytree': '0.97504', 'subsample': '0.48725', 'min_split_gain': '0.46081', 'scale_pos_weight': '4.27291', 'reg_alpha': '389.22277', 'reg_lambda': '171.09768', 'learning_rate': '0.20099'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE Loss 0.25963 params {'n_estimators': 970, 'max_depth': 118, 'num_leaves': 200, 'min_child_samples': 10, 'colsample_bytree': '0.59618', 'subsample': '0.77283', 'min_split_gain': '0.22468', 'scale_pos_weight': '3.23472', 'reg_alpha': '164.76529', 'reg_lambda': '277.67292', 'learning_rate': '0.03040'}\n",
      "NRMSE Loss 0.25716 params {'n_estimators': 654, 'max_depth': 150, 'num_leaves': 190, 'min_child_samples': 30, 'colsample_bytree': '0.52941', 'subsample': '0.52403', 'min_split_gain': '0.49997', 'scale_pos_weight': '4.50244', 'reg_alpha': '41.50257', 'reg_lambda': '107.19247', 'learning_rate': '0.04815'}\n",
      "NRMSE Loss 0.25984 params {'n_estimators': 780, 'max_depth': 136, 'num_leaves': 145, 'min_child_samples': 20, 'colsample_bytree': '0.74091', 'subsample': '0.96542', 'min_split_gain': '0.69087', 'scale_pos_weight': '6.52776', 'reg_alpha': '152.27036', 'reg_lambda': '62.92666', 'learning_rate': '0.23212'}\n",
      " 56%|████████████████████████▉                    | 111/200 [10:28<08:23,  5.66s/trial, best loss: 0.25556761857345167]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m space_lgbm \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1500\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m250\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.01\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.5\u001b[39m)),\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlgbm_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspace_lgbm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(best)\n\u001b[0;32m     21\u001b[0m best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mlgbm_objective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]),   \n\u001b[0;32m     14\u001b[0m }\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMRegressor(\n\u001b[0;32m     17\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     18\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m-\u001b[39m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     23\u001b[0m losses \u001b[38;5;241m=\u001b[39m losses \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(train_y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_01\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNRMSE Loss \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m params \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(losses\u001b[38;5;241m.\u001b[39mmean(), params))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y,\n\u001b[0;32m    889\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space_lgbm = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1500, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 250, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 200, 5),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 150, 5),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.7),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 500),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 500),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = lgbm_objective,\n",
    "            space = space_lgbm,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 200)\n",
    "\n",
    "print(best)\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best['num_leaves'] = int(best['num_leaves'])\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_child_samples'] = int(best['min_child_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a165221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'min_child_samples': int(params['min_child_samples']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'subsample': '{:.3f}'.format(params['subsample']),\n",
    "        'min_split_gain': '{:.3f}'.format(params['min_split_gain']),\n",
    "        'scale_pos_weight': '{:.3f}'.format(params['scale_pos_weight']),\n",
    "        'reg_alpha': '{:.3f}'.format(params['reg_alpha']),\n",
    "        'reg_lambda': '{:.3f}'.format(params['reg_lambda']),\n",
    "        'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **params))\n",
    "    \n",
    "    losses = np.sqrt(-cross_val_score(model, train_x, train_y['Y_01'], cv=10, scoring='neg_mean_squared_error'))\n",
    "    losses = losses / np.mean(np.abs(train_y['Y_01']))\n",
    "    \n",
    "    print(\"NRMSE Loss {:.5f} params {}\".format(losses, params))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2148240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                          | 0/500 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: \n",
      "All the 10 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py\", line 895, in fit\n",
      "    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 1517, in _lazy_init\n",
      "    params_str = param_dict_to_str(params)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 294, in param_dict_to_str\n",
      "    raise TypeError(f'Unknown type of parameter:{key}, got:{type(val).__name__}')\n",
      "TypeError: Unknown type of parameter:boosting_type, got:LGBMRegressor\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/500 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py\", line 895, in fit\n    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n    self._Booster = train(\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n    booster = Booster(params=params, train_set=train_set)\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n    train_set.construct()\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n    self._lazy_init(self.data, label=self.label,\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 1517, in _lazy_init\n    params_str = param_dict_to_str(params)\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 294, in param_dict_to_str\n    raise TypeError(f'Unknown type of parameter:{key}, got:{type(val).__name__}')\nTypeError: Unknown type of parameter:boosting_type, got:LGBMRegressor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.01\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.5\u001b[39m)),\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_rng\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(best)\n\u001b[0;32m     23\u001b[0m best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(best[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      4\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMRegressor(LGBMRegressor(n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams))\n\u001b[1;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlg_nrmse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNRMSE Loss \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m params \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss, params))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py\", line 895, in fit\n    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n    self._Booster = train(\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n    booster = Booster(params=params, train_set=train_set)\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n    train_set.construct()\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n    self._lazy_init(self.data, label=self.label,\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 1517, in _lazy_init\n    params_str = param_dict_to_str(params)\n  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py\", line 294, in param_dict_to_str\n    raise TypeError(f'Unknown type of parameter:{key}, got:{type(val).__name__}')\nTypeError: Unknown type of parameter:boosting_type, got:LGBMRegressor\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 100, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 100, 10),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 300, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 0.7),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 100),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 100),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 500,\n",
    "            rstate=np.random.default_rng(1))\n",
    "\n",
    "\n",
    "print(best)\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best['num_leaves'] = int(best['num_leaves'])\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_child_samples'] = int(best['min_child_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02049b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\AppData\\Local\\Temp\\ipykernel_9628\\1799931290.py\", line 13, in lg_nrmse\n",
      "    rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 961, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1458, in _getitem_tuple\n",
      "    tup = self._validate_tuple_indexer(tup)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 769, in _validate_tuple_indexer\n",
      "    self._validate_key(k, i)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1361, in _validate_key\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1452, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\AppData\\Local\\Temp\\ipykernel_9628\\1799931290.py\", line 13, in lg_nrmse\n",
      "    rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 961, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1458, in _getitem_tuple\n",
      "    tup = self._validate_tuple_indexer(tup)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 769, in _validate_tuple_indexer\n",
      "    self._validate_key(k, i)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1361, in _validate_key\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1452, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\AppData\\Local\\Temp\\ipykernel_9628\\1799931290.py\", line 13, in lg_nrmse\n",
      "    rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 961, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1458, in _getitem_tuple\n",
      "    tup = self._validate_tuple_indexer(tup)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 769, in _validate_tuple_indexer\n",
      "    self._validate_key(k, i)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1361, in _validate_key\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1452, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\AppData\\Local\\Temp\\ipykernel_9628\\1799931290.py\", line 13, in lg_nrmse\n",
      "    rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 961, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1458, in _getitem_tuple\n",
      "    tup = self._validate_tuple_indexer(tup)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 769, in _validate_tuple_indexer\n",
      "    self._validate_key(k, i)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1361, in _validate_key\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1452, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\AppData\\Local\\Temp\\ipykernel_9628\\1799931290.py\", line 13, in lg_nrmse\n",
      "    rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 961, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1458, in _getitem_tuple\n",
      "    tup = self._validate_tuple_indexer(tup)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 769, in _validate_tuple_indexer\n",
      "    self._validate_key(k, i)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1361, in _validate_key\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1452, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\dlwl9\\AppData\\Local\\Temp\\ipykernel_9628\\1799931290.py\", line 13, in lg_nrmse\n",
      "    rmse = mean_squared_error(gt.iloc[:,idx], preds.iloc[:,idx], squared=False)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 961, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1458, in _getitem_tuple\n",
      "    tup = self._validate_tuple_indexer(tup)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 769, in _validate_tuple_indexer\n",
      "    self._validate_key(k, i)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1361, in _validate_key\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"C:\\Users\\dlwl9\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1452, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m best \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.572280100273023\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.010283635038627429\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m180\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_samples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m135\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_split_gain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.04511227284338413\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m900\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m70\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_alpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4.406681827912319\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m20.4785600448913\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale_pos_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m8.302374117433086\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.1688669888026464\u001b[39m}\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputRegressor(LGBMRegressor(n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest))\n\u001b[1;32m----> 4\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlg_nrmse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNRMSE Loss \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m params \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss, best))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\multioutput.py:202\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\multioutput.py:44\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     42\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y,\n\u001b[0;32m    889\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best = {'colsample_bytree': 0.572280100273023, 'learning_rate': 0.010283635038627429, 'max_depth': 180, 'min_child_samples': 135, 'min_split_gain': 0.04511227284338413, 'n_estimators': 900, 'num_leaves': 70, 'reg_alpha': 4.406681827912319, 'reg_lambda': 20.4785600448913, 'scale_pos_weight': 8.302374117433086, 'subsample': 0.1688669888026464}\n",
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "    \n",
    "loss = -cross_val_score(model, train_feature, train_target, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "print(\"NRMSE Loss {:.5f} params {}\".format(loss, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tv_train_x.columns))\n",
    "print(len(tv_valid_x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a5d9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'colsample_bytree': 0.572280100273023, 'learning_rate': 0.010283635038627429, 'max_depth': 180, 'min_child_samples': 135, 'min_split_gain': 0.04511227284338413, 'n_estimators': 900, 'num_leaves': 70, 'reg_alpha': 4.406681827912319, 'reg_lambda': 20.4785600448913, 'scale_pos_weight': 8.302374117433086, 'subsample': 0.1688669888026464}\n",
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "model.fit(train_feature, train_target)\n",
    "preds = model.predict(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f2288c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30549529],\n",
       "       [1.29075044],\n",
       "       [1.36952193],\n",
       "       ...,\n",
       "       [1.39878205],\n",
       "       [1.33216841],\n",
       "       [1.37291204]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8e5d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13005677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.305495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.290750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.369522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.229990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.353248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>1.394789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>1.459305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>1.398782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>1.332168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>1.372912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7922 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     1.305495\n",
       "1     1.290750\n",
       "2     1.369522\n",
       "3     1.229990\n",
       "4     1.353248\n",
       "...        ...\n",
       "7917  1.394789\n",
       "7918  1.459305\n",
       "7919  1.398782\n",
       "7920  1.332168\n",
       "7921  1.372912\n",
       "\n",
       "[7922 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "576cf64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.611301] [1.03060427]\n"
     ]
    }
   ],
   "source": [
    "print(max(preds), min(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d2c85a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  /  Min : 1.030604271077466    ,   Min : 1.6113010015745468\n"
     ]
    }
   ],
   "source": [
    "for i in a.columns:\n",
    "    print('{}  /  Min : {}    ,   Min : {}'.format(i, min(a[i]), max(a[i])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('data/validation_test_submission.csv')\n",
    "for idx, col in enumerate(submit.columns):\n",
    "    if col=='ID':\n",
    "        continue\n",
    "    submit[col] = preds[:,idx-1]\n",
    "#submit.to_csv('data/param_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()\n",
    "\n",
    "df_indicator = pd.DataFrame()\n",
    "\n",
    "for i, k in enumerate(submit.columns):\n",
    "    if k == 'ID':\n",
    "        continue\n",
    "    y_series = ~submit[k].between(y_feature_spec_info['최소'][i-1], y_feature_spec_info['최대'][i-1])\n",
    "    if i == 1:\n",
    "        df_indicator = y_series\n",
    "    else:\n",
    "        df_indicator = df_indicator + y_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485afac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_indicator.value_counts())\n",
    "df_indicator[df_indicator==True] = 1\n",
    "df_indicator[df_indicator==False] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f02f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_valid_x['X_57'] = df_indicator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffc49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_valid_x['X_57'] = tv_valid_x['X_57'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_valid_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ccbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tv_train_x))\n",
    "print(len(tv_valid_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e3b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best = {'colsample_bytree': 0.572280100273023, 'learning_rate': 0.010283635038627429, 'max_depth': 180, 'min_child_samples': 135, 'min_split_gain': 0.04511227284338413, 'n_estimators': 900, 'num_leaves': 70, 'reg_alpha': 4.406681827912319, 'reg_lambda': 20.4785600448913, 'scale_pos_weight': 8.302374117433086, 'subsample': 0.1688669888026464}\n",
    "model = MultiOutputRegressor(LGBMRegressor(n_jobs = -1, random_state = 1, **best))\n",
    "    \n",
    "loss = -cross_val_score(model, tv_valid_x, tv_valid_y, cv=10, scoring=make_scorer(lg_nrmse, greater_is_better=False)).mean()\n",
    "print(\"NRMSE Loss {:.5f} params {}\".format(loss, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c546c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = submit.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf66776",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_nrmse(submit, tv_valid_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
